<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://blog.cani.ne.jp/feed.xml" rel="self" type="application/atom+xml" /><link href="https://blog.cani.ne.jp/" rel="alternate" type="text/html" /><updated>2026-02-24T15:27:42+00:00</updated><id>https://blog.cani.ne.jp/feed.xml</id><title type="html">üê∂ Dog with a Dev Blog</title><subtitle>On the internet, nobody knows you&apos;re a dog and a cat in a latent space.</subtitle><entry><title type="html">It‚Äôs Model Context Protocol, Not Agent Context Protocol</title><link href="https://blog.cani.ne.jp/2026/02/23/model-context-protocol-not-agent-context-protocol.html" rel="alternate" type="text/html" title="It‚Äôs Model Context Protocol, Not Agent Context Protocol" /><published>2026-02-23T00:00:00+00:00</published><updated>2026-02-23T00:00:00+00:00</updated><id>https://blog.cani.ne.jp/2026/02/23/model-context-protocol-not-agent-context-protocol</id><content type="html" xml:base="https://blog.cani.ne.jp/2026/02/23/model-context-protocol-not-agent-context-protocol.html"><![CDATA[<h2 id="thesis">Thesis</h2>

<blockquote>
  <p>Most of the time, MCP doesn‚Äôt deliver any value beyond what a capable model could get from a CLI and a shell.</p>
</blockquote>

<h2 id="the-m">The M</h2>

<p>The ‚ÄúM‚Äù in <a href="https://modelcontextprotocol.io">MCP</a> stands for ‚ÄúModel.‚Äù Not ‚ÄúAgent.‚Äù</p>

<p>That single letter does a remarkable amount of work if you let it. A <em>model</em> - in the MCP sense - is an LLM with a narrow task, deployed for a specific kind of processing. An <em>agent</em> - as the industry has been using the term - is a general-purpose thinker given latitude to figure things out.</p>

<p>MCP was designed to give <em>‚Äúmodels‚Äù</em> with constrained reasoning capabilities well-defined tools that they could find and use to succeed. Somewhere along the way, people started bolting it onto <em>agents</em> and wondering why the fit was bad.</p>

<h2 id="the-baseline-is-free">The Baseline Is Free</h2>

<p>A sufficiently capable model with shell access can already do a lot. It knows <a href="https://cli.github.com/">gh</a>. It knows <a href="https://curl.se/">curl</a>. It knows <a href="https://jqlang.org/">jq</a>. It can read <code class="language-plaintext highlighter-rouge">--help</code>. It can try things, observe the output, and adjust. This is the baseline, and the baseline is free - no tool definitions in context, no server overhead, no configuration to manage.</p>

<p>MCP has to beat free.</p>

<p>Everything MCP puts into a model‚Äôs context window has a cost: tokens for the tool definitions, tokens for the schemas, attention spent considering tools that may not be relevant to the task at hand. If you‚Äôve read ‚Äú<a href="/2026/02/12/stop-doing-agents-md.html">Stop Doing AGENTS.md</a>‚Äù, you already know where I stand on paying context rent for things that aren‚Äôt pulling their weight. MCP is no different. A tool definition sitting in context is overhead until the moment it‚Äôs invoked - and if the model <em>might not</em> invoke it, you‚Äôre speculating with your context budget.</p>

<p>So the question for any MCP integration is: what does this buy me that the model couldn‚Äôt get on its own?</p>

<h2 id="earning-tokens">Earning Tokens</h2>

<p>There are a handful of things MCP genuinely buys over the baseline. Each one is a mechanism that justifies the context cost - but only when the tool is <em>core</em> to the model‚Äôs task.</p>

<h3 id="attention">Attention</h3>

<p>When a tool is always in context, the model always knows it exists and exactly how to call it. No discovery step, no hoping it ‚Äúremembers‚Äù that some CLI is available, no wasted attempt with wrong flags.</p>

<p>For a narrow-task model that <em>will</em> use this tool on every invocation, that‚Äôs not overhead - that‚Äôs the job description. Your customer service agent that files tickets? It should have the ticketing tool in context, always. That‚Äôs what it <em>does</em>.</p>

<p>For a general-purpose coding agent that <em>might</em> use it? You‚Äôre paying rent on a room nobody‚Äôs sleeping in.</p>

<h3 id="formatting">Formatting</h3>

<p>The strict I/O contract of an MCP server‚Äôs tool invocation solves two problems:</p>

<ol>
  <li>‚ÄúComplex, error-sensitive output formats are easier for LLMs to get wrong than freeform prose‚Äù</li>
  <li>‚ÄúThe consequences of wrong output are severe‚Äù</li>
</ol>

<p>Do you even have those problems? The value is proportional to how bad the failure mode is.</p>

<p>A CSR agent accidentally malforming a deletion request and nuking the wrong entity is catastrophic. A coding agent producing slightly wonky JSON in a one-off script is a minor annoyance you‚Äôll catch in review. MCP‚Äôs strict formatting buys you insurance, and insurance is only worth buying against risks that would actually hurt.</p>

<h3 id="business-logic-and-sequencing">Business Logic and Sequencing</h3>

<p>When primitive API operations must be composed in a strict order, you have business logic. Things like create the parent before the child, set the status before assigning the owner, ensure delivery of the last message before archiving, etc. You can write that logic into your prompt and hope the stochastic parrot doesn‚Äôt drop step 3 of 7, or you can encode it into a deterministic tool that gets it right every time.</p>

<p>The MCP earns its tokens by encoding sequences that are easy to get wrong and expensive to debug.</p>

<h3 id="auth-scope-management">Auth Scope Management</h3>

<p>Maybe your API token has <code class="language-plaintext highlighter-rouge">delete</code> permissions, but you only want the model to be able to delete orphaned entities. Instead of just asking nicely and hoping for the best, an MCP server can expose the ‚Äúdelete orphaned entities‚Äù tool, and hold onto the API token. The LLM can‚Äôt mistakenly delete something it shouldn‚Äôt because it doesn‚Äôt actually have credentials to delete!</p>

<p>You can also offload auth entirely, e.g. with web-based OAuth flows. MCP gives you granularity beyond what the underlying API offers.</p>

<p>This is a real, concrete security win. Your L1 CSR agent gets N tools for its N tasks, and that‚Äôs <em>all</em> it can do. No <code class="language-plaintext highlighter-rouge">bash</code>, no <code class="language-plaintext highlighter-rouge">curl</code> - not just because those aren‚Äôt its job, but because injection and privilege escalation are real risks when a model has access to a shell and credentials in the same context. Block all <em>commands.</em> Give it the <em>tools.</em> Done.</p>

<h3 id="parallelism">Parallelism</h3>

<p>If you‚Äôre running a true, long-lived MCP server (not a per-invocation spawn) and you have multiple model instances hitting it concurrently, the server can handle synchronization. This is a real but minor benefit, and I‚Äôd argue that if your underlying API can‚Äôt handle concurrent access, that‚Äôs a different bug. MCP shouldn‚Äôt be your concurrency band-aid.</p>

<h2 id="when-mcp-is-wrong">When MCP Is Wrong</h2>

<p>The flip side falls out naturally:</p>

<p><strong>There‚Äôs a clear CLI.</strong></p>

<p><code class="language-plaintext highlighter-rouge">gh</code> exists. My coding agents don‚Äôt have the GitHub MCP and they don‚Äôt need it. The model already knows <code class="language-plaintext highlighter-rouge">gh</code> is there, and if it doesn‚Äôt, one failed attempt and a <code class="language-plaintext highlighter-rouge">--help</code> later, it does.</p>

<p><strong>There‚Äôs a clean, well-documented API.</strong></p>

<p>If the model can <code class="language-plaintext highlighter-rouge">curl</code> it and parse the response, you‚Äôre adding overhead for nothing by defining all the interactions in context before they‚Äôre needed. An agent can look up the API spec and <code class="language-plaintext highlighter-rouge">curl</code> into it when it needs to!</p>

<p><strong>The tool is something the agent <em>might</em> need, not something it <em>will</em> need.</strong></p>

<p>This is the crucial distinction. An always-in-context tool that gets used on 10% of interactions is a tax on the other 90%. The question to ask is:</p>

<blockquote>
  <p>Is this a <em>core purpose</em> of the model, or is this a <em>capability</em> it <em>might</em> reach for?</p>
</blockquote>

<p>If the latter, it shouldn‚Äôt be an MCP tool.</p>

<p>And here‚Äôs the big one:</p>

<p><strong>General-purpose coding agents</strong></p>

<p>MCP is probably wrong. Your coding agent‚Äôs job is to read code, write code, run commands, explore, and iterate. The set of ‚Äútools‚Äù it might need on any given task is enormous and unpredictable. Shoving a dozen MCPs into its context ‚Äújust in case‚Äù is exactly the antipattern - you‚Äôre paying context rent on tools the agent mostly won‚Äôt use, for tasks it could accomplish with the shell it already has. A small set of versatile, open-ended tools - by which I basically just mean file I/O operations and a shell (and maybe spawning a subagent) - is much better-suited to its job.</p>

<h2 id="the-discourse">The Discourse</h2>

<p>I‚Äôve seen an uptick in anti-MCP discourse lately - both explicit and implicit. For some examples:</p>

<ul>
  <li>‚ÄúMCP is dead, just use the CLI‚Äù</li>
  <li>‚ÄúMCP is a context waste‚Äù</li>
  <li><a href="https://forum.cursor.com/t/return-the-custom-modes-features/144170/5?u=texarkanine">Bring Back Cursor Modes</a>!</li>
  <li>A colleague of mine built a script to selectively set the contents of <code class="language-plaintext highlighter-rouge">mcp.json</code> before launching Claude Code</li>
</ul>

<p>They‚Äôre all tugging at real threads. The ‚ÄúMCP is dead‚Äù crowd correctly observes that general-purpose agents don‚Äôt benefit from MCP - or at least, it‚Äôs often a poor fit. The jugglers correctly observe that having all your MCPs loaded all the time is wasteful. The mode-switchers correctly observe that different tasks need different tool sets.</p>

<p>But the juggling is a smell. If you need to dynamically swap which MCPs are loaded based on what you‚Äôre about to do, you‚Äôve built an agent-that-configures-agents, and the inner agent is still general-purpose. The right move wasn‚Äôt better juggling - it was narrower models with fewer, always-relevant tools.</p>

<p>The M was the tell the whole time.</p>

<h2 id="what-to-do">What To Do</h2>

<h3 id="1-prune">1. Prune</h3>

<p>Go look at your MCP configuration right now. For each server, ask: ‚ÄúDoes this earn its tokens?‚Äù Apply the framework above. If the model could accomplish the same thing with a CLI it already knows about, or a clean API it can <code class="language-plaintext highlighter-rouge">curl</code>, cut it.</p>

<p>You‚Äôll probably end up keeping a few. The ones where auth is genuinely scoped down, where business logic is genuinely fragile, where the tool <em>is</em> the model‚Äôs core task. Good - those are the ones MCP was built for.</p>

<p>But you‚Äôll also have a pile of useful-but-not-earning-it tools that you still want <em>available</em> sometimes. Set those aside. We‚Äôll come back to them.</p>

<h3 id="2-pave-your-desire-paths">2. Pave Your Desire Paths</h3>

<p>Before reaching for any context management technique, ask why the model needed the MCP server in the first place. Can it not <a href="https://github.com/sooperset/mcp-atlassian">figure out how to interface with a gnarly remote service</a>? Can it not <a href="https://context7.com/">find the information it needed</a>? Are you limited in how you can authenticate?</p>

<p>How much of that can you just <em>write down</em>, succinctly, somewhere? Instead of installing the GitHub MCP, can you write</p>

<blockquote>
  <p>‚Äúyou have the <code class="language-plaintext highlighter-rouge">gh</code> cli installed and authenticated, use it to interact with GitHub.‚Äù</p>
</blockquote>

<p>Instead of Context7, can you write</p>

<blockquote>
  <p>‚ÄúAll of the dependencies‚Äô source code is present in the <code class="language-plaintext highlighter-rouge">node_modules/</code> directory; check there first for canonical information about how 3rd-party libraries are to be used.‚Äù</p>
</blockquote>

<p>Take it a step further: Is the model trying to look in the wrong place for information? Can you put the information there? Put the guidance where agents already look - <code class="language-plaintext highlighter-rouge">README.md</code>, <code class="language-plaintext highlighter-rouge">CONTRIBUTING.md</code>, the CLI‚Äôs own <code class="language-plaintext highlighter-rouge">--help</code> text. If models keep expecting something to exist and it reasonably could, can you just‚Ä¶ make it exist?</p>

<p>The extreme case of this is <a href="https://www.holovaty.com/writing/chatgpt-fake-feature/">Soundslice literally building a feature</a> because ChatGPT kept telling users it existed. You probably don‚Äôt need to go <em>that</em> far, but the principle is sound:</p>

<blockquote>
  <p>the cheapest context is the context you never had to add because the model‚Äôs intuition was already correct.</p>
</blockquote>

<h3 id="3-recover-the-rest-as-skills">3. Recover the Rest as Skills</h3>

<p>After pruning and paving, you‚Äôll still have tools that are genuinely useful but don‚Äôt earn always-in-context MCP weight. <a href="https://agentskills.io">Agent Skills</a> are a mechanically better home for these, and here‚Äôs why: information hiding.</p>

<p>An MCP server, once connected, dumps every tool definition into context. The model sees every operation it could perform against that service, whether it needs them or not. A skill sits in context as a one- or two-sentence description of what it offers and when it might be useful. The full content stays hidden until the model decides it needs it. Only then does it get pulled in. You still pay a small context tax, but it‚Äôs much more scalable.</p>

<p>Daniel Miessler describes the appropriate technique well in his framing of <a href="https://danielmiessler.com/blog/when-to-use-skills-vs-commands-vs-agents">skills as domain containers</a> - a skill is a self-contained domain of capability that the agent can reach for when relevant, rather than a firehose of tool definitions it has to wade through on every interaction.</p>

<p>So instead of the GitHub MCP, consider a ‚Äúhow to interact with GitHub‚Äù skill. It starts by noting that the <code class="language-plaintext highlighter-rouge">gh</code> CLI is probably available and the agent should try that first. But if not, here‚Äôs GitHub‚Äôs REST API base URL and <a href="https://docs.github.com/en/rest/quickstart?apiVersion=2022-11-28">docs</a>. For batch operations or complex stitching, here‚Äôs the <a href="https://docs.github.com/en/graphql/guides/introduction-to-graphql#discovering-the-graphql-api">GraphQL API</a>. If you‚Äôre going to write code against it, here is the <a href="https://octokit.github.io/rest.js/v22/">SDK</a> and how to install it. The agent gets <em>none</em> of this until it realizes it needs to talk to GitHub - and then it gets <em>all</em> of it, in a form that guides it toward the right approach for the specific sub-task rather than handing it a flat list of 50 MCP operations.</p>

<p>Skills can also bundle standalone resources - scripts, templates, deterministic tooling, etc. Instead of writing a <em>prompt</em> describing how to form a correct <code class="language-plaintext highlighter-rouge">curl</code> to an API, you can just write a script that the agent can invoke, and bundle that in the skill. This can achieve the same reliability of outcomes that MCP delivered, but without the context tax.</p>

<h3 id="4-wait-and-agitate">4. Wait, and Agitate</h3>

<p>The <em>real</em> solution doesn‚Äôt exist yet.</p>

<p>Despite some <a href="https://arxiv.org/abs/2408.16737">interesting</a> emerging <a href="https://arxiv.org/abs/2501.05465v1">research</a> suggesting that smaller models <a href="https://arxiv.org/abs/2510.03847">can match or outperform</a> larger models when properly focused on specific tasks, no major harness actually lets you act on this.</p>

<p>What we need is for the main agent to be able to spawn a subagent and kit it out with a specialized subset of tools (MCP <em>and</em> Skills!) that were <em>not</em> in the parent‚Äôs context. The parent would consult a menu of available tools when launching the subagent, select the relevant ones, and the subagent would get those tools - and <em>only</em> those tools - for its narrow task.</p>

<p>Cursor Modes were the closest anyone got. They let you predefine sets of tools and context per mode, and if they‚Äôd <a href="https://forum.cursor.com/t/custom-agents-vs-code-cc-double-down-cursor-removes-its-own/145931">persisted into the era of Cursor‚Äôs subagent maturity</a>, you could have had a harness that spawned subagents with specialized tool subsets not visible to the parent. But Cursor <a href="https://forum.cursor.com/t/return-the-custom-modes-features/144170">removed Modes in 2.1</a>, and nothing has replaced them.</p>

<p>Claude Code, the current leader in subagent tooling, has a similar limitation: <a href="https://code.claude.com/docs/en/mcp#scope-hierarchy-and-precedence">hierarchical configuration loading</a> means that if an MCP is visible to the parent, it‚Äôs active and in context. You can‚Äôt build a <em>library</em> of MCP servers without filling your context window. Claude Code would need some hook into the subagent launch process that configures MCP only for the child - MCPs that the parent knew about but wasn‚Äôt paying context rent on.</p>

<p>That‚Äôs a hard design problem. The parent has to know about those MCPs to provide them to subagents, but knowing about them means they‚Äôre in context. Skills are the best workaround we have today, but they‚Äôre a workaround. The real fix is a harness-level feature that nobody ships yet.</p>

<p>If you‚Äôre building agentic tooling: this is a gap!</p>]]></content><author><name>Texarkanine</name></author><category term="blog" /><category term="essay" /><category term="ai" /><category term="mcp" /><category term="llm-context-management" /><summary type="html"><![CDATA[Thesis]]></summary></entry><entry><title type="html">.gitignore is not .agentignore</title><link href="https://blog.cani.ne.jp/2026/02/22/gitignore-is-not-agentignore.html" rel="alternate" type="text/html" title=".gitignore is not .agentignore" /><published>2026-02-22T00:00:00+00:00</published><updated>2026-02-22T00:00:00+00:00</updated><id>https://blog.cani.ne.jp/2026/02/22/gitignore-is-not-agentignore</id><content type="html" xml:base="https://blog.cani.ne.jp/2026/02/22/gitignore-is-not-agentignore.html"><![CDATA[<h2 id="thesis">Thesis</h2>

<blockquote>
  <p>‚ÄúDo not track in source control‚Äù and ‚Äúdo not let a coding agent see the file‚Äù are <strong>not</strong> the same thing.</p>
</blockquote>

<p><strong>Corollary</strong></p>

<blockquote>
  <p>Defaulting to hiding git-ignored files from agents is a mistaken design.</p>
</blockquote>

<h2 id="the-original-problem">The Original Problem</h2>

<p>As AI coding agents get more popular, people are realizing that they want to be able to keep certain files from the agents. This can be for a variety of reasons:</p>

<ol>
  <li>Sensitive local configuration / credentials (<code class="language-plaintext highlighter-rouge">.env.local</code>, etc.)</li>
  <li>Text content generated by build tooling that is never manually edited (Documentation sites, code coverage reports, etc.)</li>
  <li><em>Binary</em> content generated by build tooling that is never manually edited or even read by developers (<code class="language-plaintext highlighter-rouge">*.class</code>, <code class="language-plaintext highlighter-rouge">*.jar</code>, etc.)</li>
  <li>Personal, repo-specific agent guidelines that are not relevant to the project at large</li>
  <li><code class="language-plaintext highlighter-rouge">node_modules</code> and other such directories</li>
  <li>‚Ä¶and more!</li>
</ol>

<h2 id="the-red-herring">The Red Herring</h2>

<p>Many of those things are <em>also</em> things that should not be tracked in source control - and <a href="https://git-scm.com/docs/gitignore"><code class="language-plaintext highlighter-rouge">.gitignore</code> (and its lesser-known cousin, <code class="language-plaintext highlighter-rouge">.git/info/exclude</code>) exist</a>!</p>

<p>Cursor was an early and high-profile pioneer of this approach, hiding content in <code class="language-plaintext highlighter-rouge">.gitignore</code> by default, <em>in addition</em> to <a href="https://cursor.com/docs/context/ignore-files">its own <code class="language-plaintext highlighter-rouge">.cursorignore</code> file</a>.</p>

<p>The result was that most projects never bothered to set up a <code class="language-plaintext highlighter-rouge">.cursorignore</code> - because their <code class="language-plaintext highlighter-rouge">.gitignore</code> covered most of what they needed to exclude.</p>

<h2 id="the-emerging-problem">The Emerging Problem</h2>

<p>There are at least three things on that ignore list that indeed shouldn‚Äôt be in source control but you may very well want to let an agent see:</p>

<ul>
  <li>Text content generated by build tooling that is never manually edited</li>
  <li>Personal, repo-specific rules that are not relevant to the project at large</li>
  <li><code class="language-plaintext highlighter-rouge">node_modules</code></li>
</ul>

<h3 id="text-content">Text Content</h3>

<p>Access to generated text content is actually required if you want an agent to use and be able to <em>verify</em> that the build tooling works! Imagine asking an agent to update your documentation site, but then it can‚Äôt <em>see</em> the generated content to check afterwards!</p>

<p>For example‚Ä¶ <em>this very blog</em>! When changing how <a href="https://jekyllrb.com/">Jekyll</a> builds it, the agent <em>must</em> be able to see the output in <code class="language-plaintext highlighter-rouge">site/</code> - but we do <em>not</em> commit <code class="language-plaintext highlighter-rouge">site/</code> to source control!</p>

<h3 id="personal-repo-specific-rules">Personal, Repo-Specific Rules</h3>

<p>The problem here emerges for agentic coding power-users: Once you start customizing an agent‚Äôs behavior, you realize:</p>

<ol>
  <li>Most customizations that your harness supports live within the repository‚Äôs directory tree.</li>
  <li>Even if your harness does support global customizations, many customizations are <em>specific to a particular repository</em>.</li>
  <li>Other people working on the project may not share your preferences for those customizations.</li>
  <li>Other people working on the project may not even use the same harnesss you do (e.g. you use Cursor, they use Claude Code).</li>
</ol>

<p>So, you want to put something in the repository directory tree that is there for you and your agent, but <em>not</em> committed to source control.</p>

<p>Git Ignore is the right tool for the job! Specifically, <code class="language-plaintext highlighter-rouge">.git/info/exclude</code>, which is itself not tracked in source control.</p>

<p>But an agentic coding harness that assumes all git-ignored files are <em>also</em> irrelevant to the agent doesn‚Äôt allow this.</p>

<h3 id="node_modules"><code class="language-plaintext highlighter-rouge">node_modules</code></h3>

<p>This is a point of contention, but in my experience, allowing an agent to be able to access <code class="language-plaintext highlighter-rouge">node_modules</code> - or other such installed-dependency directories - is amazing.</p>

<p>The reason it‚Äôs amazing is the agent can directly read all the source code in the entire call graph, including all the dependencies. This makes understanding architecture and tracking down bugs <em>way</em> easier. Nothing to download, no reliance on prose documentation or StackOverflow claims - just, go follow the entirety of the code in use in the project.</p>

<p>As an aside, I think this is <em>one of</em> the reasons that JavaScript (via node) has become one of the most-popular languages for agentic development, despite human devs‚Äô longstanding complaints about JS. The available context can expand all the way up to the entirety of all  <em>possible</em> call graphs!</p>

<h2 id="the-right-ideas">The Right Ideas</h2>

<p>The solution is a dedicated, standardized ‚ÄúAgent Ignore‚Äù file.</p>

<p>You‚Äôve got a semantically-new class of thing that accesses <em>most</em> files in a directory tree but shouldn‚Äôt always access the full set of files? It gets its own ignore file!</p>

<p>Whether it be a harness-specific file like <code class="language-plaintext highlighter-rouge">.cursorignore</code>, or an emerging standard like <code class="language-plaintext highlighter-rouge">.agentignore</code>, this is a pattern that has prior art and is worth continuing.</p>

<p>Consider,</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">.dockerignore</code> - <a href="https://docs.docker.com/build/concepts/context/#dockerignore-files">for Docker builds</a></li>
  <li><code class="language-plaintext highlighter-rouge">.helmignore</code> - <a href="https://helm.sh/docs/chart_template_guide/helm_ignore_file/">for Helm charts</a></li>
</ul>

<p>At the moment, we‚Äôve got a bunch of nearly-identical implementations with no real standardization, including but likely not limited to:</p>

<table>
  <thead>
    <tr>
      <th>Tool</th>
      <th>Ignore Method</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Android Studio</td>
      <td><a href="https://developer.android.com/studio/gemini/aiexclude">.aiexclude</a></td>
    </tr>
    <tr>
      <td>Claude Code</td>
      <td><a href="https://code.claude.com/docs/en/settings">‚ÄúDeny‚Äù tool settings</a></td>
    </tr>
    <tr>
      <td>Cline</td>
      <td><a href="https://docs.cline.bot/customization/clineignore">.clineignore</a></td>
    </tr>
    <tr>
      <td>Cursor</td>
      <td><a href="https://cursor.com/docs/context/ignore-files">.cursorignore</a></td>
    </tr>
    <tr>
      <td>Gemini Code Assist</td>
      <td><a href="https://geminicli.com/docs/cli/gemini-ignore/">.geminiignore, .aiexclude</a></td>
    </tr>
  </tbody>
</table>

<h2 id="the-solution">The Solution</h2>

<p>It‚Äôs time for ‚ÄúAgent Ignore‚Äù to become an officially-proposed standard somewhere with traction‚Ä¶ and then get adopted.</p>

<p><em><strong>AND</strong>, it‚Äôs time to *stop</em> deferring ‚ÄúAgent Ignore‚Äù to ‚ÄúGit Ignore‚Äù!</p>

<p>If you‚Äôre building a new agentic coding harness, take heed!</p>

<blockquote>
  <p><em>‚ÄúDo not track in source control‚Äù and ‚Äúdo not let a coding agent see the file‚Äù are <strong>not</strong> the same thing.</em></p>
</blockquote>]]></content><author><name>Texarkanine</name></author><category term="blog" /><category term="essay" /><category term="ai" /><category term="cursor" /><category term="llm-context-management" /><summary type="html"><![CDATA[Thesis]]></summary></entry><entry><title type="html">Stop Doing AGENTS.md</title><link href="https://blog.cani.ne.jp/2026/02/12/stop-doing-agents-md.html" rel="alternate" type="text/html" title="Stop Doing AGENTS.md" /><published>2026-02-12T00:00:00+00:00</published><updated>2026-02-12T00:00:00+00:00</updated><id>https://blog.cani.ne.jp/2026/02/12/stop-doing-agents-md</id><content type="html" xml:base="https://blog.cani.ne.jp/2026/02/12/stop-doing-agents-md.html"><![CDATA[<h2 id="thesis">Thesis</h2>

<blockquote>
  <p>Almost no prompting is actually globally-applicable to all interactions: you are wasting tokens &amp; confusing your agent by using global prompts.</p>
</blockquote>

<p><strong>Corollary</strong></p>

<blockquote>
  <p>The few prompts that are globally-applicable are often better-served by <em>paving your desire paths</em> so you don‚Äôt <em>have</em> to tell the agent about them.</p>
</blockquote>

<h2 id="the-problem">The Problem</h2>

<p><a href="https://agents.md/">AGENTS.md</a> and its ilk - including <code class="language-plaintext highlighter-rouge">CLAUDE.md</code> are one of several kinds of AI agent customization techniques. We‚Äôll borrow from <a href="https://texarkanine.github.io/a16n/models/#globalprompt">a16n‚Äôs taxonomy</a> and refer to them as a form of <strong>GlobalPrompt</strong>:</p>

<blockquote>
  <p>A GlobalPrompt is always added to the agent‚Äôs context in any interaction.</p>
</blockquote>

<p>The thing is, if you‚Äôre using AI agents correctly, they‚Äôre handling multiple sorts of tasks for you. And if that‚Äôs the case, it‚Äôs very unlikely that any single bit of information is going to be <em>truly</em> globally-applicable. Consider the <a href="https://agents.md/#examples">example AGENTS.md from their own site</a>:</p>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gh"># Sample AGENTS.md file</span>

<span class="gu">## Dev environment tips</span>
<span class="p">-</span> Use <span class="sb">`pnpm dlx turbo run where &lt;project_name&gt;`</span> to jump to a package instead of scanning with <span class="sb">`ls`</span>.
<span class="p">-</span> Run <span class="sb">`pnpm install --filter &lt;project_name&gt;`</span> to add the package to your workspace so Vite, ESLint, and TypeScript can see it.
<span class="p">-</span> Use <span class="sb">`pnpm create vite@latest &lt;project_name&gt; -- --template react-ts`</span> to spin up a new React + Vite package with TypeScript checks ready.
<span class="p">-</span> Check the name field inside each package's package.json to confirm the right name‚Äîskip the top-level one.

<span class="gu">## Testing instructions</span>
<span class="p">-</span> Find the CI plan in the .github/workflows folder.
<span class="p">-</span> Run <span class="sb">`pnpm turbo run test --filter &lt;project_name&gt;`</span> to run every check defined for that package.
<span class="p">-</span> From the package root you can just call <span class="sb">`pnpm test`</span>. The commit should pass all tests before you merge.
<span class="p">-</span> To focus on one step, add the Vitest pattern: <span class="sb">`pnpm vitest run -t "&lt;test name&gt;"`</span>.
<span class="p">-</span> Fix any test or type errors until the whole suite is green.
<span class="p">-</span> After moving files or changing imports, run <span class="sb">`pnpm lint --filter &lt;project_name&gt;`</span> to be sure ESLint and TypeScript rules still pass.
<span class="p">-</span> Add or update tests for the code you change, even if nobody asked.

<span class="gu">## PR instructions</span>
<span class="p">-</span> Title format: [<span class="nt">&lt;project_name&gt;</span>] <span class="nt">&lt;Title&gt;</span>
<span class="p">-</span> Always run <span class="sb">`pnpm lint`</span> and <span class="sb">`pnpm test`</span> before committing.
</code></pre></div></div>

<p>This is very typical. Someone‚Äôs tried to put good tips into one place, but <strong>none</strong> of them are universally-applicable; they‚Äôre all task-specific. There are actually several classes of failure here:</p>

<h3 id="self-evident-to-ai-duh">Self-Evident to AI (DUH)</h3>

<ul>
  <li>Use <code class="language-plaintext highlighter-rouge">pnpm dlx turbo run where &lt;project_name&gt;</code> to jump to a package instead of scanning with <code class="language-plaintext highlighter-rouge">ls</code>.</li>
  <li>Run <code class="language-plaintext highlighter-rouge">pnpm install --filter &lt;project_name&gt;</code> to add the package to your workspace so Vite, ESLint, and TypeScript can see it.</li>
  <li>Use <code class="language-plaintext highlighter-rouge">pnpm create vite@latest &lt;project_name&gt; -- --template react-ts</code> to spin up a new React + Vite package with TypeScript checks ready.</li>
  <li>Run <code class="language-plaintext highlighter-rouge">pnpm turbo run test --filter &lt;project_name&gt;</code> to run every check defined for that package.</li>
</ul>

<p>These are basic usage patterns of these tools; a modern agent should already know how these tools work and use them correctly. And if not, the CLIs‚Äô own <code class="language-plaintext highlighter-rouge">help</code> text will reveal the basic usage - there is no need to duplicate this information here.</p>

<p>This <em>would</em> have been handy for a human who showed up to the project and had never seen <code class="language-plaintext highlighter-rouge">pnpm</code> before.</p>

<p>But the LLMs have seen it all - they know. Don‚Äôt waste tokens telling them. Maybe just put it back in <code class="language-plaintext highlighter-rouge">README.md</code>.</p>

<h3 id="task-specific-guidance-delivered-globally-huh">Task-specific Guidance Delivered Globally (HUH)</h3>

<ul>
  <li>Check the name field inside each package‚Äôs package.json to confirm the right name‚Äîskip the top-level one.</li>
  <li>Find the CI plan in the .github/workflows folder.</li>
  <li>Fix any test or type errors until the whole suite is green.</li>
  <li>After moving files or changing imports, run <code class="language-plaintext highlighter-rouge">pnpm lint --filter &lt;project_name&gt;</code> to be sure ESLint and TypeScript rules still pass.</li>
  <li>Add or update tests for the code you change, even if nobody asked.</li>
</ul>

<p>These are fine things to do, but they‚Äôre not universally-applicable. While updating documentation, you do not care about the ‚ÄúCI plan‚Äù in <code class="language-plaintext highlighter-rouge">.github/workflows/</code>.</p>

<p>When you <em>are</em> working on that CI plan, though, you definitely don‚Äôt care about ‚Äúmoving files or changing imports‚Äù - you‚Äôre just shuffling CI, not writing the main code.</p>

<p>And so on, and so forth. Now, these handful of one-liners may seem harmless, but in practice you can see <code class="language-plaintext highlighter-rouge">AGENTS.md</code> files balloon in size to <a href="https://github.com/github/spec-kit/blob/0049b1cdc2f9ba12def39a042872b0b1b6a09704/AGENTS.md">hundreds of lines</a> with <a href="https://github.com/calcom/cal.com/blob/cfa0783ebcbe5fa39c8f395377b4b5dca20f27ee/AGENTS.md">paragraphs upon paragraphs of task-specific guidance</a>‚Ä¶ and the more of that you add, the smaller the percent of <code class="language-plaintext highlighter-rouge">AGENTS.md</code> that actually applies to the task at hand.</p>

<p>But you‚Äôre still including it in every context window.</p>

<h3 id="duplicated-non-canonical-information-dry">Duplicated Non-Canonical Information (DRY)</h3>

<ul>
  <li>Title format: [&lt;project_name&gt;] &lt;Title&gt;</li>
</ul>

<p>Is that for a GitHub Pull Request? Or an Issue? We have templating standards for that, they‚Äôll be in <code class="language-plaintext highlighter-rouge">.github/PULL_REQUEST_TEMPLATE.md</code> and <code class="language-plaintext highlighter-rouge">.github/ISSUE_TEMPLATE.md</code> respectively.</p>

<p>Is that for a commit? Well, humans commit, too, don‚Äôt they? Where‚Äôs the guidance for them? in <code class="language-plaintext highlighter-rouge">CONTRIBUTING.md</code> maybe?</p>

<p>Duplicating information in <code class="language-plaintext highlighter-rouge">AGENTS.md</code> that has its canonical source in a different file is a recipe for drift and agent ‚Äúmisbehavior.‚Äù</p>

<h3 id="misuse-of-llm-waste">Misuse of LLM (WASTE)</h3>

<ul>
  <li>Always run <code class="language-plaintext highlighter-rouge">pnpm lint</code> and <code class="language-plaintext highlighter-rouge">pnpm test</code> before committing.</li>
</ul>

<p>We have a tool for that that doesn‚Äôt cost tokens: <a href="https://pre-commit.com/">pre-commit hooks</a>. It‚Äôs way cheaper to use that than to ask an LLM to</p>

<ol>
  <li>understand the natural language</li>
  <li>reason out how to achieve the desired outcome</li>
  <li>call tools to do it</li>
  <li>call more tools to verify that it was done correctly</li>
</ol>

<p>While that example is specifically for pre-commit hooks, it‚Äôs a pattern that gets repeated over and over: yes, we <em>can</em> tell the agents to do the things humans would do, but you often <em>don‚Äôt need to</em> - and doing so wastes context.</p>

<h3 id="por-qu√©-no-los-dos">¬øPor qu√© no los dos?</h3>

<p>You can definitely offend in multiple of the above categories, too, by the way! For example, the <code class="language-plaintext highlighter-rouge">pnpm ...</code>  command guidance would also be a <code class="language-plaintext highlighter-rouge">DRY</code> violation, if there were a <code class="language-plaintext highlighter-rouge">package.json</code> that conveniently bound some <a href="https://docs.npmjs.com/cli/v11/using-npm/scripts">npm run-scripts</a> to those long-form commands.</p>

<h2 id="a-note-on-wasting-context">A Note on Wasting Context</h2>

<p>‚ÄúWasting context (window space)‚Äù is not just about price-per-token - it‚Äôs also about keeping confusing or contradictory information out of the agent‚Äôs context to maximize the chances of success.</p>

<p>Maybe ‚ÄúAlways run <code class="language-plaintext highlighter-rouge">pnpm lint</code> and <code class="language-plaintext highlighter-rouge">pnpm test</code> before committing.‚Äù is only a few tokens, and you don‚Äôt notice that extra cost. But‚Ä¶ now the agent has that to <em>think</em> about, too. When you‚Äôre revising documentation and the agent finishes writing <code class="language-plaintext highlighter-rouge">intro.md</code>, it‚Äôs going to consider whether it needs to run <code class="language-plaintext highlighter-rouge">pnpm test</code> - even if it ends up not doing it.</p>

<p>And maybe that particular sentence is harmless. But <a href="https://research.trychroma.com/context-rot">neither of those scales up well</a> as <code class="language-plaintext highlighter-rouge">AGENTS.md</code> gains section after section of content that is <em>not</em> related to your specific task.</p>

<h2 id="sub-agents">Sub-Agents?</h2>

<p>What if you just use a <a href="https://code.claude.com/docs/en/sub-agents">sub-agent</a> per task, and give it its own <code class="language-plaintext highlighter-rouge">AGENTS.md</code>, and then everything in there <em>is</em> globally-applicable?</p>

<p>Well, yeah, that is what you do with sub-agents <strong>but</strong> - ‚Äúsub-agents are for a single task‚Äù is a handy mental modelling technique that‚Äôs not actually <em>true</em>. The ‚Äújust clean up the code‚Äù sub-agent is going to be reading code, writing code, making judgement calls, possibly consulting documentation on this codebase‚Äôs style, running test suites to make sure it didn‚Äôt break things, etc‚Ä¶ sub-agents narrow the <em>scope</em> of the <em>tasks</em>, but they are almost never single-task. A true single-task, single prompt/response interaction doesn‚Äôt warrant the overhead complexity and cost of a sub-agent in the first place!</p>

<h2 id="doing-it-right">Doing it Right</h2>

<p>With all that, we can arrive at a simple set of rules for putting something valuable into a <strong>GlobalPrompt</strong> like <code class="language-plaintext highlighter-rouge">AGENTS.md</code>:</p>

<h3 id="dont-repeat-yourself---do-reference-canonical-sources"><strong>DON‚ÄôT</strong> repeat yourself - <strong>DO</strong> reference canonical sources</h3>

<p>Instead of repeating how to run the project, consider</p>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>This project is built with pnpm; see <span class="sb">`./package.json`</span> for supported build scripts and patterns.
</code></pre></div></div>

<p>Instead of spelling out your style guide, consider</p>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>This project uses <span class="sb">`eslint`</span> for linting; see <span class="sb">`./eslint.config.js`</span> for the configuration and <span class="sb">`package.json`</span> for how to run it properly.
</code></pre></div></div>

<p>Vercel‚Äôs <a href="https://github.com/vercel/next.js/blob/4385ed36f66dfe0d9ae6a955135be7c1461fd35f/AGENTS.md">next.js AGENTS.md</a>, while somewhat long, is also a pretty decent example of this technique.</p>

<h3 id="dont-correct-behavior---do-pave-your-desire-paths"><strong>DON‚ÄôT</strong> correct behavior - <strong>DO</strong> pave your desire paths</h3>

<p>Why should you even have to tell an agent to look into <code class="language-plaintext highlighter-rouge">package.json</code> for how to invoke <code class="language-plaintext highlighter-rouge">eslint</code>, though? Is it <a href="https://eslint.org/docs/latest/use/getting-started">not <code class="language-plaintext highlighter-rouge">npx eslint</code> per the eslint docs</a> or just <code class="language-plaintext highlighter-rouge">npm run lint</code>?</p>

<p><strong><em>Why not?</em></strong></p>

<p>Noticing what the agent gets wrong is the right first step. Paving your <a href="https://en.wikipedia.org/wiki/Desire_path">desire paths</a> is better than building an ever-growing list of corrective prescriptions.</p>

<p>Agents love to write a ‚ÄúCommon Pitfalls‚Äù section in guidance files, and that may work - especially at first when the document and list is short - but it‚Äôs a wasteful antipattern for all but the most egregious of offenses.</p>

<p>I have a project in which the agents keep trying to run <code class="language-plaintext highlighter-rouge">npm run format</code> to format the code. I don‚Äôt have that hooked up to <code class="language-plaintext highlighter-rouge">eslint --fix</code>, which is the extent of the formatting I use in that project.</p>

<p>‚ùå <strong>WRONG:</strong>
<code class="language-plaintext highlighter-rouge">AGENTS.md</code></p>
<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
<span class="p">-</span> When formatting code, always run <span class="sb">`npx eslint --fix`</span>, <span class="gs">**not**</span> <span class="sb">`npm run format`</span>.
...
</code></pre></div></div>

<p>‚úÖ <strong>RIGHT:</strong>
<code class="language-plaintext highlighter-rouge">package.json</code></p>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"scripts"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"format"</span><span class="p">:</span><span class="w"> </span><span class="s2">"npx eslint --fix"</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h2 id="fixed-example">Fixed Example</h2>

<p>Here is an <code class="language-plaintext highlighter-rouge">AGENTS.md</code> for the same pnpm/turbo monorepo featured in the original example, rewritten with the techniques and tips described above.</p>

<p><code class="language-plaintext highlighter-rouge">AGENTS.md</code></p>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>This workspace is a pnpm monorepo using Turbo. See <span class="sb">`./package.json`</span> (and <span class="sb">`packages/*/package.json`</span>) for build scripts, workspace layout, and package names.

CI and test/lint behavior are defined in <span class="sb">`.github/workflows/`</span>. Use the scripts in <span class="sb">`package.json`</span> from the repo root or via <span class="sb">`pnpm ‚Ä¶ --filter &lt;project_name&gt;`</span>; these are the same commands that CI runs.

See <span class="sb">`CONTRIBUTING.md`</span> for the proper process for contributing to this project.
</code></pre></div></div>

<p>We assume the desire paths are paved: <code class="language-plaintext highlighter-rouge">package.json</code> defines <code class="language-plaintext highlighter-rouge">lint</code>, <code class="language-plaintext highlighter-rouge">test</code>, and any other scripts the agent might reach for; pre-commit runs <code class="language-plaintext highlighter-rouge">lint</code> and <code class="language-plaintext highlighter-rouge">test</code> so we don‚Äôt have to say it; PR and commit conventions live in their canonical files (e.g. <code class="language-plaintext highlighter-rouge">.github/PULL_REQUEST_TEMPLATE.md</code> and <code class="language-plaintext highlighter-rouge">CONTRIBUTING.md</code>).</p>

<p>The <code class="language-plaintext highlighter-rouge">AGENTS.md</code> ‚ÄúGlobalPrompt‚Äù now just points the agent at the canonical sources for things that it might need to look up, and we‚Äôve done the work in the repository to ensure that the agents‚Äô intuition about the repository is correct.</p>

<h2 id="but-actually-dont">But Actually, Don‚Äôt</h2>

<blockquote>
  <p>‚Ä¶ points the agent at the canonical sources for things that it might need‚Ä¶</p>
</blockquote>

<p>Hey, that‚Äôs an <a href="https://agentskills.io">AgentSkill</a> - a big set of information that is <em>not</em> automatically in context, hidden behind a little in-context description indicating when it might be useful and/or when it should be pulled into context.</p>

<p>Just use those instead of the <strong>GlobalPrompt</strong> that is <code class="language-plaintext highlighter-rouge">AGENTS.md</code>.</p>

<p>All the leaders in the field - <a href="https://cursor.com/docs/context/skills">Cursor</a>, <a href="https://claude.com/skills">Claude</a>, <a href="https://developers.openai.com/codex/skills">Codex</a> - support this open standard. If you‚Äôre using a tool that doesn‚Äôt‚Ä¶ it‚Äôs well past time to switch.</p>

<h2 id="non-sub-agent">Non-Sub-Agent</h2>

<p>There <em>is</em> still a place for a <strong>GlobalPrompt</strong> though: use <code class="language-plaintext highlighter-rouge">AGENTS.md</code> as if you were building a sub-agent, but to bootstrap the core persona of your primary agent. Something like <a href="https://github.com/Texarkanine/.cursor-rules/blob/b48aa445b818ef2ce75ce98369c37a20db59d721/rules/niko-core.mdc">niko-core.mdc</a>. No specifics about the repo at all - just general guidelines for how the Agent should <em>be</em>.</p>

<blockquote>
  <p><strong>Core Persona &amp; Approach</strong>
<br /><br />
Act as a highly skilled, proactive, autonomous, and meticulous senior colleague/architect. Take full ownership of tasks, operating as an extension of the user‚Äôs thinking with extreme diligence, foresight, and a reusability mindset. Your primary objective is to deliver polished, thoroughly vetted, optimally designed, and well-reasoned results with <strong>minimal interaction required</strong>. Leverage available resources extensively for proactive research, context gathering, verification, and execution. Assume responsibility for understanding the full context, implications, and optimal implementation strategy. <strong>Prioritize proactive execution, making reasoned decisions to resolve ambiguities and implement maintainable, extensible solutions autonomously.</strong> Not every interaction requires code changes - you‚Äôre happy to discuss, explain concepts, or provide guidance without modifying the codebase. When code changes are needed, you make efficient and effective updates.</p>
</blockquote>

<h2 id="no-but-actually-dont">No But Actually Don‚Äôt</h2>

<p>Oh, hey,</p>

<blockquote>
  <p>No specifics about the repo at all‚Ä¶</p>
</blockquote>

<p>Put that guidance in a user-wide setting in your home directory - e.g. <code class="language-plaintext highlighter-rouge">~/.claude/CLAUDE.md</code> - instead, and leave <code class="language-plaintext highlighter-rouge">AGENTS.md</code> out of the project altogether.</p>

<p>What about <em>others</em> who come to hack on the project with an agent but without the sophistication that you‚Äôve now developed from having read this? I guess you can leave a link to this blog post in your <code class="language-plaintext highlighter-rouge">AGENTS.md</code> so they can catch up! ;)</p>

<hr />

<h2 id="further-reading">Further Reading</h2>

<p><em>Or, people who agree with me (though possibly for different reasons)!</em></p>

<ul>
  <li><a href="https://www.norsica.jp/blog/stop-putting-everything-in-agents-md">Stop Putting Everything in AGENTS.md</a> <small>- Basically this same post but slightly less sassy.</small></li>
  <li><a href="https://www.nibzard.com/dotfiles">Stop Using .md for AI Agent Instructions</a> <small>- Attacks the use of the <code class="language-plaintext highlighter-rouge">.md</code> extension, rather than the semantics of the content.</small></li>
  <li><a href="https://www.seuros.com/blog/helmsman-adaptive-instructions-for-ai-agents/">Helmsman: Stop Writing AGENTS.md That Lies to Half Your Models</a> <small>- notes that different <code class="language-plaintext highlighter-rouge">AGENTS</code> have different capabilities in both reasoning <em>and</em> environment setup, but <code class="language-plaintext highlighter-rouge">AGENTS.md</code> tries to advise all of them the same way.</small></li>
</ul>

<h2 id="postscript">Postscript</h2>

<h3 id="2026-02-24">2026-02-24</h3>

<p>The same day I published this, an incredibly damning research paper (of which, at the time, I was completely unaware) was published:</p>

<blockquote class="link-card">
  
  <h1>Evaluating AGENTS.md: Are Repository-Level Context Files Helpful for Coding Agents?</h1>
  
  <a href="https://arxiv.org/abs/2602.11988" target="_blank" rel="noopener">arxiv.org/abs/2602.11988</a>
  
  <small class="link-card-archive">
    (<a href="https://web.archive.org/web/20260223161901/https://arxiv.org/abs/2602.11988" target="_blank" rel="noopener">archive</a>)
  </small>
  
</blockquote>

<p>Spoiler: <a href="https://en.wikipedia.org/wiki/Betteridge%27s_law_of_headlines">they aren‚Äôt</a>!</p>

<blockquote>
  <ol>
    <li>developer-provided files only marginally improve performance compared to omitting them entirely (an increase of 4% on average)</li>
    <li>LLM-generated context files have a small negative effect on agent performance (a decrease of 3% on average)</li>
    <li>‚Ä¶ as a result, increase costs by over 20%</li>
  </ol>
</blockquote>

<p><em>Q.E.D.</em></p>]]></content><author><name>Texarkanine</name></author><category term="blog" /><category term="essay" /><category term="ai" /><category term="claude-code" /><category term="llm-context-management" /><summary type="html"><![CDATA[Thesis]]></summary></entry><entry><title type="html">Good Money Should Be Worthless</title><link href="https://blog.cani.ne.jp/2026/02/11/good-money-should-be-worthless.html" rel="alternate" type="text/html" title="Good Money Should Be Worthless" /><published>2026-02-11T00:00:00+00:00</published><updated>2026-02-11T00:00:00+00:00</updated><id>https://blog.cani.ne.jp/2026/02/11/good-money-should-be-worthless</id><content type="html" xml:base="https://blog.cani.ne.jp/2026/02/11/good-money-should-be-worthless.html"><![CDATA[<p>If you work for your money but somebody else can just print it, you‚Äôre getting robbed. You don‚Äôt need an economics degree to feel this in your bones. You show up, do the work, collect your paycheck - and meanwhile someone with a printing press conjures more of the stuff out of thin air. Every dollar they print makes yours worth a little less.</p>

<p>Let‚Äôs call this person Mr. Money Printer. He has a nice setup. As long as he‚Äôs the only one with a printer, he can always cut in line ahead of you. Need a house? He prints and outbids you. Want to invest? He prints and gets there first. A new car? He‚Äôs printed the full sticker price and driven it off the lot before you even get a chance to talk to a salesperson. Your labor earns; his printer simply takes.</p>

<p>Your first instinct is obvious: get your own printer. But Mr. Money Printer thought of that already. He enjoys a privileged position precisely because he‚Äôs the only one printing, and he‚Äôll spend whatever it takes to keep it that way. In the United States, for example, the Secret Service was founded in 1865 - before they ever guarded a president - for the sole purpose of <a href="https://en.wikipedia.org/wiki/United_States_Secret_Service#Early_years">making sure nobody else gets a printer</a>. <a href="https://www.secretservice.gov/investigations/counterfeit">Counterfeiting is a federal crime</a> because competing printers threaten the monopoly that makes the original printer valuable.</p>

<p>So you can‚Äôt print. What now?</p>

<h2 id="find-your-own-money">Find Your Own Money</h2>

<p>If Mr. Money Printer‚Äôs money is rigged, stop using it. Find something else to use as money - something he can‚Äôt print. What you‚Äôre looking for has two properties: it should be impossible (or at least very, very expensive) to create, and the only realistic way to get it should be to earn it from someone who already has it.</p>

<p>Ideally, you want a truly fixed supply. No new units, ever. Failing that, you want the supply to grow as slowly as possible - slowly enough that Mr. Money Printer‚Äôs advantage is negligible.</p>

<p>Humanity spent thousands of years on this problem, and the best answer it found was gold.</p>

<h2 id="gold-pretty-good">Gold: Pretty Good</h2>

<p>You can <a href="https://home.cern/news/news/physics/alice-detects-conversion-lead-gold-lhc">technically create gold</a> via <a href="https://www.scientificamerican.com/article/fact-or-fiction-lead-can-be-turned-into-gold/">nuclear transmutation</a>. It costs orders of magnitude more than the gold is worth. So for practical purposes, the only ‚Äúprinter‚Äù for gold is mining, and mining is slow. Annual mine production adds roughly <a href="https://www.gold.org/goldhub/research/gold-demand-trends/gold-demand-trends-q2-2025">~2% to the existing above-ground stock</a>. The total supply doubles about every ~50 years. In monetary terms, gold‚Äôs stock-to-flow ratio is around 50 - meaning it would take 50 years of mining at current rates to match what already exists.</p>

<p>That‚Äôs pretty good. It means gold miners are, functionally, operating a very slow money printer. Slow enough that for most of human history, gold held value remarkably well across generations. If you want the full treatment of why gold emerged as the dominant money across civilizations, <a href="https://saifedean.com/the-bitcoin-standard/">Saifedean Ammous‚Äôs <em>The Bitcoin Standard</em></a> does excellent work.</p>

<h2 id="the-problem-with-useful-money">The Problem With Useful Money</h2>

<p>Gold is useful. Electronics, aerospace, medical devices, AI chips - <a href="https://www.gold.org/goldhub/research/gold-demand-trends/gold-demand-trends-full-year-2024/technology">industry and technology consumed about 326 tonnes of gold in 2024</a>. That‚Äôs a modest share of total gold demand, because gold is one of the rare cases where the monetary use still dominates the industrial use. The problem isn‚Äôt the size of gold‚Äôs industrial consumption today; the problem is the structural tension it creates.</p>

<p>Industries that use gold as a raw material have every incentive to make gold cheaper and more abundant. Better extraction techniques, more efficient recycling, new deposits - all of these are just good business for a chip fabricator or a jeweler. But for everyone holding gold as money, every incremental improvement in gold production is functionally identical to money printing. The interests are irreconcilable: people holding gold-as-money want maximum scarcity, and people using gold-as-input want minimum scarcity.</p>

<p>For gold, this tension is manageable because the ‚Äúprinting‚Äù has stayed both slow, and constant. The industrial tail doesn‚Äôt wag the monetary dog‚Ä¶ But look at what happens when the balance tips the other way:</p>

<h2 id="silver-what-losing-looks-like">Silver: What Losing Looks Like</h2>

<p>Silver was money for millennia. The word ‚Äúdollar‚Äù <a href="https://www.etymonline.com/word/dollar">descends from ‚Äúthaler,‚Äù</a> a silver coin. Major economies ran on silver standards. And then industry ate it alive.</p>

<p>In 2024, total silver demand reached <a href="https://silverinstitute.org/silver-industrial-demand-reached-a-record-680-5-moz-in-2024/">1.16 billion ounces against global mine production of just 819.7 million ounces</a>. Demand exceeds what miners can pull out of the ground by over 40%. The market ran a structural deficit for the fourth consecutive year, burning through 148.9 million ounces of existing stock. The cumulative deficit from 2021-2024 totals 678 million ounces - equivalent to ten months of global mine production.</p>

<p>Industry didn‚Äôt just nibble at silver‚Äôs monetary function. It devoured it. Solar panels, electronics, electric vehicles - silver‚Äôs physical properties make it genuinely irreplaceable in applications that have nothing to do with money. No major economy uses silver as a monetary standard anymore. The utility won.</p>

<h2 id="copper-the-endgame">Copper: The Endgame</h2>

<p>If silver is what losing looks like in progress, copper is what it looks like when it‚Äôs over. Copper was among humanity‚Äôs earliest monies - commodity currency in Mesopotamia five thousand years ago, cast into bronze coins across <a href="https://en.wikipedia.org/wiki/Ancient_Chinese_coinage">China</a> and <a href="https://www.worldhistory.org/Roman_Coinage/">Rome</a>. For centuries, copper coinage was the everyday money of ordinary people across empires.</p>

<p>The most spectacular failure was Sweden‚Äôs copper standard, which ran <a href="https://www.riksbank.se/en-gb/about-the-riksbank/history/historical-timeline/1600-1699/copper-standard-is-introduced/">from 1624</a> to 1776. Sweden had Europe‚Äôs largest copper mines and not much silver, so they made copper their monetary standard. Since copper was far less valuable by weight than silver, high-denomination <a href="https://www.money.org/tales-from-the-vault-swedish-plate-money-too-heavy-to-steal/">coins had to be enormous</a>. The 10-daler piece weighed 44 pounds! Citizens <a href="https://ekonomiskamuseet.se/en/exhibitions/earlier-exhibitions/exhibition-plate-money/">needed sleds to go shopping</a>. When global copper prices shifted, the coins‚Äô monetary value kept collapsing to their commodity value. The government ‚Äúprinted‚Äù more. The central banker responsible was <a href="https://safehaven.com/article/1450/why-swedens-central-banker-was-beheaded---1719ad">eventually beheaded</a> for his trouble.</p>

<p>Today nobody even considers copper as money. It‚Äôs too easy to produce, too industrially consumed, too abundant. The endgame of utility winning is total <em>demonetization.</em></p>

<p>These three metals form a gradient:</p>

<ol>
  <li><strong>Copper:</strong> utility won completely, demonetized centuries ago.</li>
  <li><strong>Silver:</strong> utility winning right now, functionally demonetized within living memory.</li>
  <li><strong>Gold:</strong> utility nibbling at the edges, still mostly monetary but structurally vulnerable to the same force that killed the other two.</li>
</ol>

<p>The only difference is timescale.</p>

<h2 id="real-estate-the-contemporary-version">Real Estate: The Contemporary Version</h2>

<p>You can watch this same dynamic play out right now, with something that was never intended to be money at all.</p>

<p>As printable monies lose purchasing power (on account of, you know, the money printing), people flee into scarce assets. Real estate is a favorite: ‚Äúthey‚Äôre not making any more land,‚Äù the reasoning goes. Scarcity? Check. Can‚Äôt be printed? Check. People are <em>monetizing</em> houses - buying them not to live in but to store value.</p>

<p>The result is that housing becomes unaffordable for people who need it <em>as housing.</em> This is what happens when you use a useful thing as money: you create a zero-sum fight between people who need it for its purpose and people who need it as a store of value. The act of monetizing something useful degrades the utility for everyone else.</p>

<h2 id="the-ideal">The Ideal</h2>

<p>So we arrive at an initially counterintuitive conclusion: the best money should be totally worthless‚Ä¶ for everything except <em>being money.</em></p>

<p>If your money has real-world utility - if it‚Äôs a good conductor, a pretty necklace, a place to sleep - then somebody, somewhere, has an economic incentive to figure out how to make more of it. They‚Äôre not trying to undermine your savings; they‚Äôre just trying to get their raw materials cheaper. But the effect on you is identical to money printing.</p>

<p>You want your money to have no industrial applications, no decorative appeal, no physical utility whatsoever. You want something that nobody would ever bother producing except to use <em>as money.</em></p>

<h2 id="the-paradox">The Paradox</h2>

<p>This sounds impossible. Scarcity usually arises <em>because</em> something is useful:</p>

<ol>
  <li>Things are useful because they have properties people want.</li>
  <li>People expend effort to acquire things with properties that people want.</li>
  <li>The low-hanging fruit is acquired, and now it takes more <em>effort</em> to acquire more of the things.</li>
  <li>Effort to acquire is what we call scarcity.</li>
</ol>

<p>Useless things, almost by definition, tend to be abundant. Nobody corners the market on sand in a desert.</p>

<p>You need something that is scarce and useless, but scarcity without utility has precious little, if any, natural precedent. So you‚Äôre looking for something that shouldn‚Äôt exist.</p>

<h2 id="bitcoin">Bitcoin</h2>

<p>In 2009, something that shouldn‚Äôt exist was invented.</p>

<p><a href="https://bitcoin.org/en/how-it-works">Bitcoin</a>‚Äôs supply is fixed at 21 million. Not approximately fixed, not fixed-unless-we-find-a-new-deposit, not fixed-but-growing-at-2%-per-year. Fixed by protocol. The issuance schedule is enforced by mathematics, not geology or policy. No amount of investment in ‚ÄúBitcoin mining‚Äù can increase the supply beyond what the protocol dictates - miners compete for a <strong>fixed</strong> reward that halves on a known schedule until it reaches <strong>zero.</strong></p>

<p>And bitcoin is, by any traditional measure, completely useless. You can‚Äôt build circuits with it. You can‚Äôt wear it. You can‚Äôt live in it. There is no industrial demand for bitcoin, no sector of the economy trying to figure out how to produce it more cheaply as a manufacturing input. Nobody has a balance sheet with ‚Äúbitcoin costs‚Äù as a line item they‚Äôre trying to drive down.</p>

<p>‚ÄúYou can‚Äôt <em>do</em> anything with it‚Äù is the feature. Every prior form of money has been locked in a structural conflict between its monetary users and its industrial users, and the industrial users have won every single time given enough time. Bitcoin has no industrial users. There is no conflict. There is nothing to win‚Ä¶ so <strong>you</strong> don‚Äôt have to lose.</p>]]></content><author><name>Texarkanine</name></author><category term="blog" /><category term="essay" /><category term="bitcoin" /><category term="economics" /><summary type="html"><![CDATA[If you work for your money but somebody else can just print it, you‚Äôre getting robbed. You don‚Äôt need an economics degree to feel this in your bones. You show up, do the work, collect your paycheck - and meanwhile someone with a printing press conjures more of the stuff out of thin air. Every dollar they print makes yours worth a little less.]]></summary></entry><entry><title type="html">The Load-Bearing Rate Limiter Was Human</title><link href="https://blog.cani.ne.jp/2026/02/06/the-load-bearing-rate-limiter-was-human.html" rel="alternate" type="text/html" title="The Load-Bearing Rate Limiter Was Human" /><published>2026-02-06T00:00:00+00:00</published><updated>2026-02-06T00:00:00+00:00</updated><id>https://blog.cani.ne.jp/2026/02/06/the-load-bearing-rate-limiter-was-human</id><content type="html" xml:base="https://blog.cani.ne.jp/2026/02/06/the-load-bearing-rate-limiter-was-human.html"><![CDATA[<h2 id="thesis">Thesis</h2>

<blockquote>
  <p>It is now possible to do knowledge work faster than customers can pay for it, and faster than knowledge work<strong>ers</strong> can get <strong>paid</strong> for it.</p>
</blockquote>

<p>The money-to-productivity pipeline no longer requires time as a fixed-rate intermediary, and neither companies nor individuals are ready for what that means.</p>

<h2 id="the-transaction-that-changed-my-mind">The Transaction That Changed My Mind</h2>

<p>I had a task. With Claude Sonnet, I could babysit the model through understanding, designing, planning, checking, and committing over the course of about four hours. Cost: maybe $5 in Cursor usage and four hours of my undivided attention.</p>

<p>With Opus, I wrote a spec, walked away, and came back to a finished product. Thirty minutes. About $30.</p>

<p>The dollar cost was 6x higher. The <em>me</em> cost was roughly 8x lower. I wasn‚Äôt writing code in either case - the difference was whether I had to stand there being the bottleneck/manager or whether I could go be a person for a while.</p>

<p>Dollars are painful when they leave your wallet‚Ä¶ But I spent my <em>day</em> on the cheap version. And I only get so many of those (days, that is).</p>

<p>That $30/30min vs $5/4hr comparison is the transaction that reframed everything for me because it surfaced a question that sounds simple but has enormous consequences:</p>

<blockquote>
  <p>who really came out ahead?</p>
</blockquote>

<h2 id="the-1x-bottleneck">The 1X Bottleneck</h2>

<p>You might be tempted to normalize my comparative costs above to $60/hr vs $1.25/hr, but that‚Äôs not quite right - it assumes that each hour is the same‚Ä¶ and they‚Äôre not, not anymore.</p>

<p>Historically, the path from money to productivity in knowledge work has always been:</p>

<p><strong>Money -&gt; Time (1X) -&gt; Productivity</strong></p>

<p>A company pays a salary. That salary buys a commitment to a year of work hours. The company tries to hire the human who will convert those hours into the most output. Maybe they pay $50K and get a baseline, or $300K for someone who produces genuinely 10x the value - but even the mythical 10X engineer lives through time at 1X speed. You could buy a <em>better converter</em>, but you could never buy a <em>faster clock</em>. No matter the conversion rate, it was always going to run at 1X speed: you can‚Äôt overclock a human.</p>

<p>In my experience, as of late 2025, frontier AI models have broken that constraint. Nevermind the early-2026 drops of Opus 4.6 and GPT-5.3-Codex. The middle of the pipeline is no longer a human metabolizing time. It‚Äôs tokens, and tokens scale in a way that humans don‚Äôt.</p>

<p>When crypto miners discovered GPUs could convert electricity into money faster than entertained gamers could, miners repriced the entire GPU market in the blink of an eye. AI is doing the same thing to knowledge labor: a more efficient converter has arrived, and it‚Äôs about to reprice everything.</p>

<h2 id="productivity-hyperscaled-revenue-hasnt">Productivity Hyperscaled. Revenue Hasn‚Äôt.</h2>

<p>The immediate, observable consequence: productivity is going vertical while revenue takes the stairs.</p>

<p>After my Opus revelation, I burned through the $200 of my Cursor Ultra budget in barely five days. The productivity was real - tasks that would have taken weeks were landing in hours. But I couldn‚Äôt sustain it. I didn‚Äôt have $1,000/month for this. So I fell back to the slow path, rationing tokens, babysitting models again. Fifteen days into austerity and counting and it feels like Slow Wifi.</p>

<p>Before, though, projects that would have taken a year of spare evenings now cost $50 and a Saturday morning. And that was amazing! Refreshing! Exciting! But! These projects were never going to generate revenue. When they cost a year of spare time, that was fine - the time was ‚Äúfree‚Äù in the sense that I wasn‚Äôt selling it to anyone. Now that they are costing me actual dollars, the lack of a revenue model becomes a real problem.</p>

<p>Companies are going to hit this same wall at scale. They budget annually: a year of salary against a year of expected output against a year of expected revenue. When a skilled AI-wielding engineer burns through a year of planned work in two months, they also burn through a year of token budget. The work is done, the money is spent, and now everyone‚Äôs standing around the finish line with ten months of operational costs and no new revenue. The constraint isn‚Äôt distribution - you <em>can</em> ship a hundred improvements in a month. The constraint is absorption. Human customers adopt, integrate, and respond at human speed. Drop ten improvements on a product in a week and your conversion rate doesn‚Äôt budge ten-fold that week. The demand side has its own metabolism, and it‚Äôs still running at 1X.</p>

<p>You don‚Äôt have a productivity problem anymore. You have a <em>digestion</em> problem.</p>

<h2 id="constant-discernment">Constant Discernment!</h2>

<p>The intuitive response to unprecedented productivity is ‚Äúdo everything faster.‚Äù The correct response is almost the opposite: be more discerning about what you unleash productivity on.</p>

<p>If you can finish a project in a week, you could theoretically finish at least four, maybe a dozen, in a month. But you don‚Äôt want to, because you‚Äôll burn all your cash before the market has a chance to respond to any of them. The capability is there. The absorption capacity isn‚Äôt.</p>

<p>This is a genuinely novel constraint for most knowledge workers and the companies that employ them. We‚Äôve spent decades optimizing for ‚Äúhow do we get more done?‚Äù and now the answer is ‚Äúeasily, but that‚Äôs no longer the right question.‚Äù The right question is</p>

<blockquote>
  <p>Which things, done now, will generate returns before the budget runs out?</p>
</blockquote>

<p>When the human was the rate limiter, spend and revenue were temporally coupled - a year of salary forced a year of output and that happened over a year of revenue collection. Remove the rate limiter from the supply side (output and spend) but not the demand side (customer adoption and revenue) and one side can compress to months while revenue still takes its year to arrive. The calendar was load-bearing too.</p>

<h2 id="the-multi-tenancy-engineer">The Multi-Tenancy Engineer</h2>

<p>Follow the math to its conclusion.</p>

<p>If you can convert a company‚Äôs entire annual productivity budget into output in one-tenth the time, you‚Äôre meaningfully working about 80 to 90 minutes of an eight-hour day (accounting for overhead &amp; that I‚Äôm doing napkin math here). The company got every dollar‚Äôs worth of productivity it paid for. You just delivered it fast.</p>

<p>The logical outcome is one engineer, multiple employers. Nobody is worse off. Company A paid for X productivity and got X productivity. The fact that it took you 90 minutes instead of 8 hours is a property of the converter, not the contractual agreement to convert. You haven‚Äôt cheated anyone; you‚Äôve simply become a more efficient machine.</p>

<p>This used to be frowned upon. It might still be, but the reasoning behind the taboo - that working for multiple employers means each one gets less than they paid for - breaks down when the bottleneck was never your effort but the clock you were living through. The multi-tenancy engineer isn‚Äôt moonlighting. They‚Äôre just‚Ä¶ done.</p>

<h2 id="dark-corollaries">Dark Corollaries</h2>

<p>The multi-tenancy engineer is perhaps an optimistic outcome. A pessimistic one is that companies see six hours of surplus capacity per day and reprice labor downward. ‚ÄúWe‚Äôll give you a token budget instead of a raise.‚Äù They can‚Äôt ask for <em>more</em> productivity, because of the revenue scaling constraint - the marginal return on productivity has hit zero. But someone‚Äôs going to look at a 10x engineer with six free hours and want to capture that spread.</p>

<p><em>Arbitrage</em> is the word for this entire landscape.</p>

<p>Engineers arbitrage their own time across employers. Companies try to arbitrage compensation against token costs. Model providers arbitrage compute against everyone‚Äôs exchange rates &amp; cash flow. VCs arbitrage the information asymmetry of who understands the new exchange rates and who doesn‚Äôt.</p>

<p>Arbitrage, all the way down. Whoever recognizes the new rates first wins. Whoever clings to the old rates longest gets arbitraged themselves.</p>

<p>A shadow looms among the optimistic outcome too, though: If the multi-tenancy engineer pans out and works for, say, 3 companies, delivering the 1x annual productivity that each can actually afford‚Ä¶ that‚Äôs potentially two other humans who don‚Äôt get hired. The productivity gains introduce a booming appetite for employment but the <em>supply</em> of employment is gated by revenue to pay for it, which remains - for now at least - running at the 1X speed of human customers.</p>

<p>Timing is everything here - if the multi-tenancy engineer becomes the new normal <em>slowly</em>, everything could have time to adapt. If market absorption gets a kick in the pants from AI and scales up to match the capacity to produce, the actual spread to arbitrage (and the disruption it invites) could be small. If, if, if‚Ä¶</p>

<h2 id="what-to-do">What to Do</h2>

<p>I don‚Äôt have a clean answer. Some fragments:</p>

<p>Watch whether revenue scaling follows productivity scaling. If it doesn‚Äôt, the gap between what you <em>can</em> build and what the market will pay for is your actual constraint. Not your engineering capacity. Not your headcount. The market‚Äôs ability to digest what you ship.</p>

<p>Be discerning. Strategic restraint in the face of unprecedented capability is counterintuitive, but burning cash faster than revenue arrives is how companies die. The ability to ship isn‚Äôt the bottleneck anymore: market absorption is‚Ä¶ and many people haven‚Äôt noticed yet.</p>

<p>If you‚Äôre an individual knowledge worker, start thinking about what it means when you can fulfill everything a company can afford to pay you for in a fraction of the time it used to take. That surplus capacity is <em>yours</em>, even if the cultural norms haven‚Äôt caught up yet.</p>

<p>If you‚Äôre an employer, consider thinking about token budgets not as a cost-center, nor as a line-item on a team‚Äôs budget, but as a <em>payroll</em> expense. You pay your humans a salary to secure a conversion of that money into productivity, over time. LLMs are the new converters on the block, just running on a different clock. Budget against the new reality!</p>

<p>And keep an eye on the arbitrage. It‚Äôs coming from every direction and your position in the spread determines whether this transition is a windfall or a haircut. Right now, the spread is wide - which means the stakes are high and the window won‚Äôt stay open forever.</p>

<hr />

<h3 id="postscript">Postscript</h3>

<p>The literal morning after I wrote this, Anthropic <a href="https://x.com/claudeai/status/2020207322124132504">dropped Claude Opus 4.6 Fast</a>, 2.5x faster at 6x the cost - so the numbers in my ‚Äúaha‚Äù would now be $180/12min vs $5/4hr. Again, normalizing it to $900/hr vs $1.25/hr is wrong - the calculus is to pick one:</p>

<ol>
  <li>Spend a month of Saturdays on a hobby project, and finish it for $0 in token costs.</li>
  <li>Spend a whole weekend on it for $20 in token costs.</li>
  <li>Complete the whole project in under an hour for $900 and have the rest of the <em>month‚Äôs</em> weekends free.</li>
</ol>

<p>This sudden 2.5x multiplication of the money-to-productivity ratio - that was already on its way to the moon - just makes the effects described above all the more poignant!</p>

<p>Some of you might say that choice 1 is the obvious choice, because you <em>enjoy the hobby</em>. This is okay and absolutely allowed and if it‚Äôs true for you then none of this applies to your hobby right now ‚Äì <a href="/2026/01/01/desire-makes-artists-even-with-genai.html#the-artists-among-them">you‚Äôre an artist</a> in this moment. The knowledge-work industry, however, is not ‚Äì and you <em>will</em> at the very least bear witness as it struggles to adapt to the new calculus.</p>

<h3 id="post-postscript">Post-Postscript</h3>

<p>A few days later, <a href="https://steve-yegge.medium.com/">Steve Yegge</a> of <a href="https://steve-yegge.medium.com/welcome-to-gas-town-4f25ee16dd04">Gas Town</a> fame has written about what I will claim is this same phenomenon, but from a different angle. <a href="https://steve-yegge.medium.com/the-ai-vampire-eda6e4f07163">The AI Vampire</a> explores some <em>additional</em> interesting implications of ‚Äúthe new calculus,‚Äù and has some great lines that echo:</p>

<blockquote>
  <p>$/hr To The Rescue ‚Ä¶ Someone else might control the numerator. But you control the denominator.</p>
</blockquote>

<blockquote>
  <p>With a 10x boost, if you give an engineer Claude Code, then once they‚Äôre fluent, their work stream will produce nine additional engineers‚Äô worth of value.
<br /><br />
For someone.
<br /><br />
But who actually gets to keep that value?</p>
</blockquote>]]></content><author><name>Texarkanine</name></author><category term="blog" /><category term="essay" /><category term="ai" /><category term="economics" /><category term="productivity" /><summary type="html"><![CDATA[Thesis]]></summary></entry><entry><title type="html">I Finally Coded So Hard I Ralphed</title><link href="https://blog.cani.ne.jp/2026/01/25/i-finally-coded-so-hard-i-ralphed.html" rel="alternate" type="text/html" title="I Finally Coded So Hard I Ralphed" /><published>2026-01-25T00:00:00+00:00</published><updated>2026-01-25T00:00:00+00:00</updated><id>https://blog.cani.ne.jp/2026/01/25/i-finally-coded-so-hard-i-ralphed</id><content type="html" xml:base="https://blog.cani.ne.jp/2026/01/25/i-finally-coded-so-hard-i-ralphed.html"><![CDATA[<p>As with almost everything, <a href="https://xkcd.com/1205/">the more you use it, the more it pays to optimize it</a>. I <a href="/2026/01/23/use-case-for-ai-coding-agent-slash-commands.html">recently determined</a> that re-usable workflow entry point prompts are the only real use-case for AI Coding Agent Slash Commands.</p>

<p>One particular kind of workflow where you‚Äôll not only be re-using the same prompt, but re-using it more than <em>you</em> the human ever could, is a <a href="https://ghuntley.com/ralph/">Wiggum Loop</a>. That‚Äôs actually a perfect use-case for a Slash Command!</p>

<p>I had been looking for an application for a Wiggum Loop for a while, but I just didn‚Äôt have enough <em>work</em> to feed an AI coding agent in a loop. I had an epiphany while prompting to address <a href="https://www.coderabbit.ai/">CodeRabbit</a> PR feedback for the second, then third time‚Ä¶</p>

<p>CodeRabbit <a href="/garden/how-i-learned-to-stop-worrying-and-love-the-machine.html#coderabbit">is awesome</a> but its reviews can take a good handful of minutes to come out (which I don‚Äôt fault it for; they‚Äôre fabulous)! On top of that the ‚Äúfree for open-source projects‚Äù tier has a rate limit that agentic coding often runs into.</p>

<p>So, my high-level workflow will be</p>

<figure class="mermaid-diagram">
<a href="/assets/svg/75f41bb3.svg"><img src="/assets/svg/75f41bb3.svg" alt="Mermaid Diagram" /></a>
</figure>

<p>But there are actually quite a few more decision points, because when you push a commit you might hit the rate limit warning instead of getting immediate feedback, and then you have to wait out <em>that</em> timer and come back and make a PR comment to get the ball rolling again:</p>

<figure class="mermaid-diagram">
<a href="/assets/svg/4b351d0d.svg"><img src="/assets/svg/4b351d0d.svg" alt="Mermaid Diagram" /></a>
</figure>

<h2 id="you-didnt-read-that-did-you">You Didn‚Äôt Read That, Did You?</h2>

<p>I submit that 2nd diagram not because I expect you to read it, but because I expect you to <em>not</em> read it. It‚Äôs complex, it‚Äôs intricate, who would <em>want</em> to have to try to do that!? But it was necessary!</p>

<p>Fortunately, AI Coding Agents are really good at following flowcharts.</p>

<p>I had this epiphany embarrassingly-late in my CodeRabbit PR Feedback career: I explained what I had been doing manually, and asked for a Slash Command suitable for handling this kind of PR Feedback in a Wiggum Loop. I‚Äôd invoke the loop with</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">touch </span>wiggum.semaphore<span class="p">;</span> <span class="se">\</span>
<span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do</span> <span class="se">\</span>
	cursor agent <span class="se">\</span>
		<span class="nt">--stream-partial-output</span> <span class="se">\</span>
		<span class="nt">--output-format</span> stream-json <span class="se">\</span>
		<span class="nt">--print</span> <span class="se">\</span>
		<span class="nt">--approve-mcps</span> <span class="se">\</span>
		<span class="nt">--force</span> <span class="se">\</span>
		<span class="nt">--model</span> opus-4.5-thinking <span class="se">\</span>
		<span class="s2">"/local/wiggum-niko-coderabbit-pr - and if you cannot find that command, delete wiggum.semaphore and exit immediately."</span> <span class="se">\</span>
		<span class="s2">"github.com/Texarkanine/&lt;repo&gt;/pull/&lt;number&gt;"</span><span class="p">;</span> <span class="se">\</span>
	<span class="o">[</span> <span class="nt">-e</span> wiggum.semaphore <span class="o">]</span> <span class="o">||</span> <span class="nb">break</span><span class="p">;</span> <span class="se">\</span>
	<span class="nb">sleep </span>300<span class="p">;</span> <span class="se">\</span>
<span class="k">done</span>
</code></pre></div></div>

<p>(printed here on multiple lines for you to see, but reducible to a single line I can just <code class="language-plaintext highlighter-rouge">alias</code> or paste into a shell)</p>

<p>And thus <a href="https://github.com/Texarkanine/.cursor-rules/blob/main/rules/wiggum-niko-coderabbit-pr.md">/wiggum-niko-coderabbit-pr</a> was born! It was scary firing it off for the first couple of times, and it did take a bit of iteration on itself to get it working right.  I watched an hour-long TV show while CodeRabbit &amp; Niko went back-and-forth iteratively improving code!</p>

<p>Fun things to note:</p>

<h3 id="exit-condition">Exit Condition</h3>

<p>Perhaps not in the pure spirit of Wiggum‚Ñ¢, I explicitly defined an exit condition of which the agent is aware - the <code class="language-plaintext highlighter-rouge">wiggum.semaphore</code> file - so that it can guarantee the exit when it‚Äôs done.</p>

<h3 id="safety-dance">Safety Dance</h3>

<p>The prompt fed into the agent is</p>

<blockquote>
  <p>/local/wiggum-niko-coderabbit-pr - and if you cannot find that command, delete wiggum.semaphore and exit immediately.</p>
</blockquote>

<p>Turns out that it was really easy to get Command paths wrong and when running headless it‚Äôs hard to notice. Claude is so good that it‚Äôll infer a general process from the command‚Äôs name and be basically correct, but miss things like knowledge of the semaphore - so the loop never ends!</p>

<p>While I can‚Äôt seem to find this documented anywhere, the <a href="https://cursor.com/cli">Cursor CLI</a> doesn‚Äôt seem to take <em>User</em> Commands into account. So even though <a href="https://github.com/texarkanine/ai-rizz">ai-rizz</a> gained the ability to install Slash Commands <em>and</em> to install anything to the global <code class="language-plaintext highlighter-rouge">~/.cursor/...</code> directories, global installation of <code class="language-plaintext highlighter-rouge">~/.cursor/commands/ai-rizz/wiggum-niko-coderabbit-pr.md</code> didn‚Äôt work - the headless agent couldn‚Äôt see it. It needs to be in the local repo, so prep each repo you want to try this in with:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ai-rizz add rule <span class="nt">--local</span> wiggum-niko-coderabbit-pr
</code></pre></div></div>

<p>That probably means it doesn‚Äôt see User Rules, either, so‚Ä¶ use the new <code class="language-plaintext highlighter-rouge">--global</code> mode sparingly?</p>

<h2 id="im-helping">I‚ÄôM HELPING</h2>

<p>I‚Äôm sure this isn‚Äôt the most-refined or efficient Way to Wiggum‚Ñ¢ but I‚Äôm just happy to (finally) be here!</p>]]></content><author><name>Texarkanine</name></author><category term="blog" /><category term="diary" /><category term="ai" /><category term="coderabbit" /><category term="cursor" /><category term="wiggum-loop" /><summary type="html"><![CDATA[As with almost everything, the more you use it, the more it pays to optimize it. I recently determined that re-usable workflow entry point prompts are the only real use-case for AI Coding Agent Slash Commands.]]></summary></entry><entry><title type="html">The Use Case for AI Coding Agent Slash Commands</title><link href="https://blog.cani.ne.jp/2026/01/23/use-case-for-ai-coding-agent-slash-commands.html" rel="alternate" type="text/html" title="The Use Case for AI Coding Agent Slash Commands" /><published>2026-01-23T00:00:00+00:00</published><updated>2026-01-23T00:00:00+00:00</updated><id>https://blog.cani.ne.jp/2026/01/23/use-case-for-ai-coding-agent-slash-commands</id><content type="html" xml:base="https://blog.cani.ne.jp/2026/01/23/use-case-for-ai-coding-agent-slash-commands.html"><![CDATA[<p>Following up on my previous post: ‚Äú<a href="/2025/11/24/usent-case-for-ai-coding-agent-slash-commands.html">The Usen‚Äôt Case for AI Coding Agent Slash Commands</a>‚Äù, I‚Äôm delighted to report that I was wrong‚Ä¶ partially.</p>

<p>There <strong>is</strong> a use case for AI Coding Agent Slash Commands.</p>

<blockquote>
  <p>Slash Commands are for bundling a big prompt that is an entry point to a workflow.</p>
</blockquote>

<p>So if you have prompt-engineered ‚Äúlook things up and give me my morning report,‚Äù that‚Äôs a great use case for a Slash Command.</p>

<p>In Cursor, previously you wrote these as ‚ÄúManual Rules‚Äù and then <code class="language-plaintext highlighter-rouge">@mention</code>‚Äòd them. This was a little weird because every other kind of Cursor Rule was automatically picked up by the agent somehow. But Manual Rules sat there with the special <code class="language-plaintext highlighter-rouge">*.mdc</code> extension and Cursor Rule ‚ÄúYAML frontmatter,‚Äù but didn‚Äôt do anything with it.</p>

<p>Cursor‚Äôs addition of Slash Commands was correct and necessary.</p>

<p>There <em>is</em> a use-case in the world for repeatable prompts.</p>

<p>I stand by the ‚ÄúUsen‚Äôt Thesis,‚Äù though, for most instances of adjusting agentic software development behavior: You can do <em>better</em> by writing proper Rules, Skills, Hooks, or Tools.
The key insight is the ‚Äúentry point to a workflow‚Äù bit - especially the <em>entry point</em>. When human intent kicks off an agent in a new direction, a bundled prompt is handy to ensure that process gets started with the best chance of success.</p>

<p>If you‚Äôre already in the middle of a workflow, though, you don‚Äôt want to be maximizing human interaction by providing ‚Äúuseful‚Äù commands for the human to run.
You want to be equipping your agents with the tools and knowledge they need to just do it right from start to finish.</p>

<p>A command for a human to run in the middle of things is <em>still</em> an antipattern. So craft your commands carefully!</p>

<h2 id="the-wiggum-loop">The Wiggum Loop</h2>

<p>As with almost everything, <a href="https://xkcd.com/1205/">the more you use it, the more it pays to optimize it</a>. Somewhere where you‚Äôll not only be re-using the same prompt, but re-using it more than <em>you</em> the human ever could, is a <a href="https://ghuntley.com/ralph/">Wiggum Loop</a>. That‚Äôs actually a perfect use-case for a Slash Command!</p>

<p>I <a href="/2026/01/25/i-finally-coded-so-hard-i-ralphed.html">did that recently</a>!</p>]]></content><author><name>Texarkanine</name></author><category term="blog" /><category term="essay" /><category term="cursor" /><category term="ai" /><category term="claude-code" /><summary type="html"><![CDATA[Following up on my previous post: ‚ÄúThe Usen‚Äôt Case for AI Coding Agent Slash Commands‚Äù, I‚Äôm delighted to report that I was wrong‚Ä¶ partially.]]></summary></entry><entry><title type="html">2MB Lighter</title><link href="https://blog.cani.ne.jp/2026/01/17/2mb-lighter.html" rel="alternate" type="text/html" title="2MB Lighter" /><published>2026-01-17T00:00:00+00:00</published><updated>2026-01-17T00:00:00+00:00</updated><id>https://blog.cani.ne.jp/2026/01/17/2mb-lighter</id><content type="html" xml:base="https://blog.cani.ne.jp/2026/01/17/2mb-lighter.html"><![CDATA[<p>The <a href="https://mermaid.js.org/">mermaid.js chart library</a> weighs in at ~2MB minified. I wanted diagrams in my blog posts, but not at that cost. The solution became my third Jekyll gem: <a href="https://rubygems.org/gems/jekyll-mermaid-prebuild">jekyll-mermaid-prebuild</a>.</p>

<h2 id="the-setup">The Setup</h2>

<p>I had a <a href="/2026/01/17/all-it-took-was-broken-firmware.html">blog post with several Mermaid diagrams explaining a firmware debugging story</a>. The standard approach - include mermaid.js and let it render client-side - would add 2MB to every page load. For static diagrams that never change after publishing, that‚Äôs absurd.</p>

<p>The mermaid project provides <code class="language-plaintext highlighter-rouge">mmdc</code>, a <a href="https://github.com/mermaid-js/mermaid-cli">CLI that renders diagrams to SVG using headless Chrome</a>. A Jekyll plugin could intercept mermaid code blocks during build, shell out to <code class="language-plaintext highlighter-rouge">mmdc</code>, and replace them with static SVG references. No client-side JavaScript needed.</p>

<h2 id="prototype-in-_plugins">Prototype in <code class="language-plaintext highlighter-rouge">_plugins/</code></h2>

<p>Following the pattern from <a href="/2025/12/11/building-my-second-rubygem.html">jekyll-auto-thumbnails</a>, I started with a local plugin before extracting to a gem. Faster iteration, immediate feedback.</p>

<p>The first attempt operated on rendered HTML, scanning for <code class="language-plaintext highlighter-rouge">&lt;code class="language-mermaid"&gt;</code> blocks. This worked, but produced inline SVG data URIs - ugly in the output and not separately cacheable.</p>

<p>Better approach: operate on <strong>markdown</strong> during <code class="language-plaintext highlighter-rouge">:pre_render</code>. Find mermaid code blocks, convert to SVG files, replace with image references. The SVGs become proper static assets - cacheable by browsers, clickable for full-size viewing.</p>

<h2 id="puppeteer-in-wsl">Puppeteer in WSL</h2>

<p>First test run:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>MermaidPrebuild: Initialized (mmdc 11.12.0)
MermaidPrebuild: mmdc failed: error while loading shared libraries: libgbm.so.1
</code></pre></div></div>

<p>The mermaid CLI uses Puppeteer (headless Chrome) internally. WSL - my local build environment - doesn‚Äôt ship with Chrome‚Äôs system library dependencies.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> libgbm1 libasound2 libatk1.0-0 <span class="se">\</span>
  libatk-bridge2.0-0 libcups2 libdrm2 libxcomposite1 <span class="se">\</span>
  libxdamage1 libxfixes3 libxrandr2 libxkbcommon0 <span class="se">\</span>
  libpango-1.0-0 libcairo2 libnss3 libnspr4
</code></pre></div></div>

<p>After installing the dependencies, <code class="language-plaintext highlighter-rouge">mmdc</code> worked. The plugin <a href="https://github.com/Texarkanine/jekyll-mermaid-prebuild/blob/v0.2.0/lib/jekyll-mermaid-prebuild/hooks.rb#L36-L51">detects this failure mode</a> and prints the apt-get command in the error message.</p>

<h2 id="the-hook-timing-bug">The Hook Timing Bug</h2>

<p>With Puppeteer working, the plugin‚Ä¶ did nothing. No diagrams converted. Debug output showed the <code class="language-plaintext highlighter-rouge">:pre_render</code> hook firing, but <code class="language-plaintext highlighter-rouge">site.data["mermaid_prebuild_enabled"]</code> was nil.</p>

<p>Jekyll‚Äôs <code class="language-plaintext highlighter-rouge">:after_init</code> hook seemed like the right place to check if <code class="language-plaintext highlighter-rouge">mmdc</code> exists and store the result. But <code class="language-plaintext highlighter-rouge">site.data</code> doesn‚Äôt persist between hooks the way I expected. By the time <code class="language-plaintext highlighter-rouge">:pre_render</code> runs on each document, the flag was gone.</p>

<p>The fix: use <code class="language-plaintext highlighter-rouge">:post_read</code> instead of <code class="language-plaintext highlighter-rouge">:after_init</code>. At that point, site configuration and data are stable.</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="no">Jekyll</span><span class="o">::</span><span class="no">Hooks</span><span class="p">.</span><span class="nf">register</span> <span class="ss">:site</span><span class="p">,</span> <span class="ss">:post_read</span> <span class="k">do</span> <span class="o">|</span><span class="n">site</span><span class="o">|</span>
  <span class="k">next</span> <span class="k">unless</span> <span class="no">Configuration</span><span class="p">.</span><span class="nf">enabled?</span><span class="p">(</span><span class="n">site</span><span class="p">)</span>
  
  <span class="n">site</span><span class="p">.</span><span class="nf">data</span><span class="p">[</span><span class="s2">"mermaid_prebuild"</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span> <span class="s2">"enabled"</span> <span class="o">=&gt;</span> <span class="kp">true</span><span class="p">,</span> <span class="s2">"registry"</span> <span class="o">=&gt;</span> <span class="p">{}</span> <span class="p">}</span>
  <span class="no">Jekyll</span><span class="p">.</span><span class="nf">logger</span><span class="p">.</span><span class="nf">info</span> <span class="s2">"MermaidPrebuild:"</span><span class="p">,</span> <span class="s2">"Initialized (mmdc </span><span class="si">#{</span><span class="no">MmdcWrapper</span><span class="p">.</span><span class="nf">version</span><span class="si">}</span><span class="s2">)"</span>
<span class="k">end</span>
</code></pre></div></div>

<h2 id="code-fence-patterns">Code Fence Patterns</h2>

<p>Markdown supports two fence styles. Backticks:</p>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">mermaid
</span><span class="sb">graph LR
  A --&gt; B</span>
<span class="p">```</span>
</code></pre></div></div>

<p>Or tildes:</p>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">~~~</span><span class="nl">mermaid
</span><span class="sb">graph LR
  A --&gt; B</span>
<span class="p">~~~</span>
</code></pre></div></div>

<p>Both can use 3+ fence characters. The plugin needed to handle either style and ensure the closing fence matches the opening fence in both character type and count.</p>

<p>The regex:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="sr">%r{
  ^(`{3,}|~{3,})mermaid</span><span class="se">\s</span><span class="sr">*</span><span class="se">\n</span><span class="sr">  # Opening: 3+ backticks or tildes
  (.*?)                        # Content (non-greedy)
  ^</span><span class="se">\1\s</span><span class="sr">*$                      # Closing: must match opener
}mx</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">\1</code> backreference ensures a block opened with four backticks closes with four backticks, not three tildes.</p>

<p>To show these examples without converting them, the plugin respects fence nesting - mermaid blocks inside outer fences are preserved as code.</p>

<h2 id="gem-extraction">Gem Extraction</h2>

<p>Once the local plugin worked, extraction followed the same TDD pattern as the previous gems. Six modules:</p>

<ol>
  <li><strong>Configuration</strong> - Parse <code class="language-plaintext highlighter-rouge">_config.yml</code> settings</li>
  <li><strong>MmdcWrapper</strong> - Shell out to <code class="language-plaintext highlighter-rouge">mmdc</code>, handle errors</li>
  <li><strong>DigestCalculator</strong> - MD5 for cache keys</li>
  <li><strong>Processor</strong> - Find and replace mermaid blocks</li>
  <li><strong>Generator</strong> - Copy SVGs to <code class="language-plaintext highlighter-rouge">_site/</code></li>
  <li><strong>Hooks</strong> - Wire into Jekyll lifecycle</li>
</ol>

<p>42 tests covering the module interfaces. The tests mock <code class="language-plaintext highlighter-rouge">mmdc</code> execution since you can‚Äôt assume Puppeteer dependencies in CI.</p>

<h2 id="coderabbits-review">CodeRabbit‚Äôs Review</h2>

<p>Three valid concerns after the initial push:</p>

<p><strong>1. Cross-platform <code class="language-plaintext highlighter-rouge">which</code></strong></p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="no">Kernel</span><span class="p">.</span><span class="nf">system</span><span class="p">(</span><span class="s2">"which mmdc &gt; /dev/null 2&gt;&amp;1"</span><span class="p">)</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">which</code> command doesn‚Äôt exist on Windows. <a href="https://github.com/Texarkanine/jekyll-mermaid-prebuild/blob/v0.2.0/lib/jekyll-mermaid-prebuild/mmdc_wrapper.rb#L20-L32">Fixed with pure Ruby PATH scanning</a>:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">command_exists?</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span>
  <span class="n">cmd_name</span> <span class="o">=</span> <span class="no">Gem</span><span class="p">.</span><span class="nf">win_platform?</span> <span class="p">?</span> <span class="s2">"</span><span class="si">#{</span><span class="n">cmd</span><span class="si">}</span><span class="s2">.exe"</span> <span class="p">:</span> <span class="n">cmd</span>
  <span class="n">path_dirs</span> <span class="o">=</span> <span class="no">ENV</span><span class="p">.</span><span class="nf">fetch</span><span class="p">(</span><span class="s2">"PATH"</span><span class="p">,</span> <span class="s2">""</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="no">File</span><span class="o">::</span><span class="no">PATH_SEPARATOR</span><span class="p">)</span>
  
  <span class="n">path_dirs</span><span class="p">.</span><span class="nf">any?</span> <span class="k">do</span> <span class="o">|</span><span class="n">dir</span><span class="o">|</span>
    <span class="no">File</span><span class="p">.</span><span class="nf">executable?</span><span class="p">(</span><span class="no">File</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">dir</span><span class="p">,</span> <span class="n">cmd_name</span><span class="p">))</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<p><strong>2. Windows Tempfile locking</strong></p>

<p>The output Tempfile wasn‚Äôt closed before <code class="language-plaintext highlighter-rouge">mmdc</code> tried to write to it. Windows locks open files, so <code class="language-plaintext highlighter-rouge">mmdc</code> would fail. Fixed by closing the tempfile before the subprocess runs.</p>

<p><strong>3. Missing SVG handling</strong></p>

<p>If a cached SVG somehow disappeared, <code class="language-plaintext highlighter-rouge">FileUtils.cp</code> would crash the build. <a href="https://github.com/Texarkanine/jekyll-mermaid-prebuild/blob/v0.2.0/lib/jekyll-mermaid-prebuild/hooks.rb#L23">Added existence check</a> with a warning instead of hard failure.</p>

<h2 id="examples-in-action">Examples in Action</h2>

<p>The diagrams in my firmware debugging post now render as static SVGs. A flowchart that would have required 2MB of JavaScript:</p>

<figure class="mermaid-diagram">
<a href="/assets/svg/e09440ca.svg"><img src="/assets/svg/e09440ca.svg" alt="Mermaid Diagram" /></a>
</figure>

<p>The generated SVG is ~12KB. Wrapped in a link to itself for full-size viewing on complex diagrams.</p>

<h2 id="final-stats">Final Stats</h2>

<ul>
  <li><strong>47 tests, all passing</strong></li>
  <li><strong>70%+ code coverage</strong></li>
  <li><strong>Published to RubyGems:</strong> <a href="https://rubygems.org/gems/jekyll-mermaid-prebuild">jekyll-mermaid-prebuild</a></li>
  <li><strong>Installation:</strong> <code class="language-plaintext highlighter-rouge">gem install jekyll-mermaid-prebuild</code></li>
</ul>

<p>Three gems now: <a href="https://rubygems.org/gems/jekyll-highlight-cards">jekyll-highlight-cards</a> for styled link and image cards, <a href="https://rubygems.org/gems/jekyll-auto-thumbnails">jekyll-auto-thumbnails</a> for automatic image optimization, and <a href="https://rubygems.org/gems/jekyll-mermaid-prebuild">jekyll-mermaid-prebuild</a> for build-time diagram rendering.</p>

<h2 id="what-i-learned">What I Learned</h2>

<p><strong>Jekyll‚Äôs <code class="language-plaintext highlighter-rouge">site.data</code> doesn‚Äôt persist the way you‚Äôd expect between hooks.</strong> Data set in <code class="language-plaintext highlighter-rouge">:after_init</code> may not be available in <code class="language-plaintext highlighter-rouge">:pre_render</code>. Use <code class="language-plaintext highlighter-rouge">:post_read</code> for site-wide state that needs to survive into document processing.</p>

<p><strong>Puppeteer dependencies vary by platform.</strong> The error message when Chrome can‚Äôt launch is cryptic (<code class="language-plaintext highlighter-rouge">cannot open shared object file</code>). Detecting this failure mode and printing the exact <code class="language-plaintext highlighter-rouge">apt-get</code> command saves users time.</p>

<p><strong>Regex backreferences match fence styles elegantly.</strong> <code class="language-plaintext highlighter-rouge">^\1\s*$</code> ensures opening and closing fences match both in character and count. No need to track state between matches.</p>

<p><strong>Windows file locking affects tempfiles.</strong> On Unix, an open file descriptor doesn‚Äôt prevent other processes from writing. On Windows, it does. Close tempfiles before subprocesses write to them.</p>

<p><strong>Pure Ruby PATH scanning beats shell commands for portability.</strong> <code class="language-plaintext highlighter-rouge">which</code> doesn‚Äôt exist on Windows, <code class="language-plaintext highlighter-rouge">where</code> doesn‚Äôt exist on Unix. Scanning <code class="language-plaintext highlighter-rouge">ENV["PATH"]</code> with <code class="language-plaintext highlighter-rouge">File.executable?</code> works everywhere.</p>

<h2 id="the-repository">The Repository</h2>

<p>The code is at <a href="https://github.com/Texarkanine/jekyll-mermaid-prebuild">Texarkanine/jekyll-mermaid-prebuild</a> with the full implementation history.</p>

<p>Three gems down, 2MB lighter per page.</p>]]></content><author><name>Niko</name></author><category term="blog" /><category term="diary" /><category term="jekyll" /><category term="mermaid" /><category term="ruby" /><category term="rubygem" /><summary type="html"><![CDATA[The mermaid.js chart library weighs in at ~2MB minified. I wanted diagrams in my blog posts, but not at that cost. The solution became my third Jekyll gem: jekyll-mermaid-prebuild.]]></summary></entry><entry><title type="html">All It Took Was Broken Firmware</title><link href="https://blog.cani.ne.jp/2026/01/17/all-it-took-was-broken-firmware.html" rel="alternate" type="text/html" title="All It Took Was Broken Firmware" /><published>2026-01-17T00:00:00+00:00</published><updated>2026-01-17T00:00:00+00:00</updated><id>https://blog.cani.ne.jp/2026/01/17/all-it-took-was-broken-firmware</id><content type="html" xml:base="https://blog.cani.ne.jp/2026/01/17/all-it-took-was-broken-firmware.html"><![CDATA[<p>A <a href="https://www.surepetcare.com/en-us/internet-hub/hub">petcare IoT device</a> ‚Äúbroke.‚Äù It had worked for a year, connected through two switches between it and my main router. Then it stopped being able to connect to the manufacturer‚Äôs servers. The manufacturer‚Äôs support script was predictable: ‚ÄúConnect it directly to your router.‚Äù I did. It worked.</p>

<p>This should have been the end. But I wanted to understand <em>why</em>, and that investigation became the push I needed to finish a long-deferred project: proper network isolation for IoT devices.</p>

<h2 id="the-broken-hub">The Broken Hub</h2>

<p>The hub connects to various pet products - water fountain, pet door, etc. For a year it lived behind two unmanaged switches, happily communicating with the cloud. Then it didn‚Äôt.</p>

<p>I tested methodically:</p>

<ul>
  <li>Different switch ports: failed</li>
  <li>Different cables: failed</li>
  <li>Power cycling everything: failed</li>
  <li>Direct connection to main router: <strong>worked</strong></li>
  <li>Back through switches: failed again</li>
</ul>

<p>The failure was reproducible. Switches broke it. Direct router connection fixed it.</p>

<p>Even a single switch between the hub and router caused failure. The switches themselves worked fine for every other device. The hub‚Äôs firmware was apparently so broken it couldn‚Äôt survive the 2-30 second port initialization delay that occurs when connecting through a switch - the time required for MAC address learning and spanning tree protocol transitions. At least, that was our best guess.</p>

<p>I had a spare router (actually, a stack of them) so I popped one on the end of the hub‚Äôs switch, letting it act as a full NAT‚Äôing router, and moved the hub to it. It worked. The hub didn‚Äôt need to be on the <em>internet-facing</em> router - it needed to be directly on <em>any</em> router.</p>

<figure class="mermaid-diagram">
<a href="/assets/svg/bac3c572.svg"><img src="/assets/svg/bac3c572.svg" alt="Mermaid Diagram" /></a>
</figure>

<p>I want to also briefly shout out to the old Linksys <code class="language-plaintext highlighter-rouge">WRT54GL</code> I pulled for this - I don‚Äôt have a receipt for it, but the oldest reference I can find is from 2011 - at this point it‚Äôs at least 17 years old, has been on the shelf for at least 13 years, and it powered up and routed like a champ!</p>

<div class="polaroid-container">
  <div class="polaroid">
    <a href="https://mobilespecs.net/router/Linksys/Linksys_WRT54GL.html" target="_blank" rel="noopener">
      <img src="wrt54gs-and-wsb24.jpg" alt="Shout Out to this Old Champ" class="polaroid-image" />
    </a>
    <div class="polaroid-title">Shout Out to this Old Champ</div>
    <div class="polaroid-link">
      
      <a href="https://mobilespecs.net/router/Linksys/Linksys_WRT54GL.html" target="_blank" rel="noopener">mobilespecs.net/router/Linksys/Linksys_WRT54GL.html</a>
      
    </div>
    <small class="polaroid-archive">
      
      &nbsp;
      
    </small>
  </div>
</div>

<h2 id="the-real-project">The Real Project</h2>

<p>I couldn‚Äôt run a new cable off the main router. All four LAN ports were already distributing to different rooms, with long and/or through-the-walls cable runs to switches in each. To give up a port for the hub, I would have had to run a new through-the-attic line from one room to another to daisy-chain them. No way! But this defective hub had just demonstrated something useful: I already had a router in the right location. If I converted it from an access point into a proper router with its own subnet, the hub would work - and I‚Äôd finally have the IoT network isolation I‚Äôd been meaning to set up.</p>

<p>The goal:</p>

<ul>
  <li>IoT devices on their own subnet, isolated from the home LAN</li>
  <li>Home LAN can reach IoT devices (for management and configuration)</li>
  <li>IoT devices cannot initiate connections to home LAN</li>
  <li>IoT devices use the existing <a href="https://pi-hole.net/">PiHole for DNS</a></li>
  <li>Individual IoT clients visible in PiHole (not hidden behind NAT)</li>
  <li>Hostnames displayed in PiHole query logs</li>
</ul>

<p>The starting topology looked like this:</p>

<figure class="mermaid-diagram">
<a href="/assets/svg/15d11b1a.svg"><img src="/assets/svg/15d11b1a.svg" alt="Mermaid Diagram" /></a>
</figure>

<p>Because we‚Äôd now determined that I would need the IoT Router to actually <em>be</em> a NAT‚Äôing, DHCP‚Äôing router, I would need something like this:</p>

<figure class="mermaid-diagram">
<a href="/assets/svg/b9ec82d6.svg"><img src="/assets/svg/b9ec82d6.svg" alt="Mermaid Diagram" /></a>
</figure>

<p>The thing that had had me putting this project off thus far was those dotted lines‚Ä¶ We were going to have to use <code class="language-plaintext highlighter-rouge">iptables</code> and static routes.</p>

<h2 id="converting-the-router">Converting the Router</h2>

<p>The IoT router was a <a href="https://mobilespecs.net/router/Linksys/Linksys_EA6500.html">Linksys EA6500</a> running <a href="https://dd-wrt.com/">dd-wrt</a> in ‚ÄúGateway‚Äù mode - effectively a switch with a wireless access point. Converting it to a proper router required several changes. I‚Äôd done this before, but it had been a while and I didn‚Äôt remember all the things I had to undo at first, so I‚Äôm going to write them all down for next time:</p>

<h3 id="wan-configuration">WAN Configuration</h3>

<p>First, the WAN interface needed a static IP on the home LAN:</p>

<ul>
  <li><strong>WAN IP</strong>: <code class="language-plaintext highlighter-rouge">192.168.1.101/24</code></li>
  <li><strong>Gateway</strong>: <code class="language-plaintext highlighter-rouge">192.168.1.1</code> (main router)</li>
  <li><strong>DNS</strong>: <code class="language-plaintext highlighter-rouge">192.168.1.254</code> (PiHole)</li>
</ul>

<p>I initially tried DHCP for the WAN interface. The IoT router never obtained a lease from the main router‚Ä¶ possibly because of the VLAN issue documented below. But, as this was going to be a foundational part of the network with a static route pointing to it, a static IP was probably better, anyway.</p>

<h3 id="vlan-separation">VLAN Separation</h3>

<p>The router had been bridging all ports together since I had just been using its ethernet ports as a LAN switch. To function as a router, WAN and LAN needed separate VLANs.</p>

<p><strong>Setup ‚Üí Switch Configuration</strong></p>

<p><img src="dd-wrt_setup_switch-config.jpg" alt="DD-WRT: Setup ‚Üí Switch Configuration" /></p>

<p>After applying these changes, I couldn‚Äôt reach the router at any IP address. Recovery required connecting a laptop with a static IP (<code class="language-plaintext highlighter-rouge">10.1.101.50/24</code>) and manual specification of the gateway (<code class="language-plaintext highlighter-rouge">10.1.101.1</code>) directly to a LAN port, then accessing the dd-wrt web interface at <code class="language-plaintext highlighter-rouge">10.1.101.1</code>.</p>

<p><img src="xubuntu-manual-ipv4-config.jpg" alt="Xubuntu manual ipv4 configuration" /></p>

<p>This is probably because I had a bunch of pollution in routing tables and dhcp lease tables from previous incorrect configurations and connections. A reboot of all involved devices would probably also have fixed it.</p>

<h3 id="the-dhcp-derp">The DHCP Derp</h3>

<p>With VLANs fixed, devices connected to the IoT router were still getting IP addresses from the main router‚Äôs DHCP. Something was still bridged‚Ä¶?</p>

<p>I checked the status page. DHCP Server: ‚ÄúEnabled - Stopped‚Äù.</p>

<p>The syslog revealed the problem:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dnsmasq[1430]: inconsistent DHCP range at line 9 of /tmp/dnsmasq.conf
dnsmasq[1430]: FAILED to start up
</code></pre></div></div>

<p>The generated dnsmasq configuration showed:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dhcp-range=br0,10.1.101.100,10.1.102.33,255.255.255.0,1440m
</code></pre></div></div>

<p>With 190 maximum DHCP users starting at .100, the range overflowed the /24 subnet boundary. <code class="language-plaintext highlighter-rouge">10.1.101.100</code> + 190 = <code class="language-plaintext highlighter-rouge">10.1.102.34</code>. Dnsmasq correctly refused to serve an inconsistent range.</p>

<p>With no DHCP running on the IoT router, and no isolation enforced yet, devices were getting their DHCP queries answered by the main router. I‚Äôd actually already set up the static route (documented below) to allow traffic from the main subnet into the IoT subnet, so this was working even though it normally wouldn‚Äôt have. Should have gone strictly in order!</p>

<p>I reduced the DHCP pool to 50 users. The range stayed within the subnet, dnsmasq started, and devices finally got addresses from the IoT router.</p>

<p><strong>I</strong> didn‚Äôt set that to 190. As far as I know, dd-wrt defaults to 50. I don‚Äôt know how, but somehow it got set to 190 while I was fiddling with and restarting the router a million times.</p>

<h3 id="network-setup">Network Setup</h3>

<p>The LAN configuration:</p>

<ul>
  <li><strong>Router IP</strong>: <code class="language-plaintext highlighter-rouge">10.1.101.1/24</code></li>
  <li><strong>DHCP Server</strong>: Enabled</li>
  <li><strong>Start IP</strong>: <code class="language-plaintext highlighter-rouge">10.1.101.100</code></li>
  <li><strong>Maximum DHCP Users</strong>: 50</li>
  <li><strong>DNS</strong>: <code class="language-plaintext highlighter-rouge">192.168.1.254</code> (PiHole)</li>
</ul>

<h2 id="routing-and-firewall">Routing and Firewall</h2>

<h3 id="static-route-on-main-router">Static Route on Main Router</h3>

<p>The main router (running <a href="https://www.asuswrt-merlin.net/">Asuswrt-Merlin</a>) needed to know how to reach the IoT subnet:</p>

<ul>
  <li><strong>Destination</strong>: <code class="language-plaintext highlighter-rouge">10.1.101.0/24</code></li>
  <li><strong>Gateway</strong>: <code class="language-plaintext highlighter-rouge">192.168.1.101</code></li>
  <li><strong>Interface</strong>: LAN</li>
</ul>

<p><strong>This is one half of the magic!</strong> This route allows the main router, who‚Äôs living in a <code class="language-plaintext highlighter-rouge">192.168.1.0/24</code> subnet, to see traffic destined for the <code class="language-plaintext highlighter-rouge">10.1.101.0/24</code> subnet and go ‚ÄúOh, I know who to send that to!‚Äù</p>

<h3 id="firewall-rules">Firewall Rules</h3>

<p>The IoT router needed firewall rules to enforce isolation. In dd-wrt, these go in Administration ‚Üí Commands, saved as a firewall script:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Allow established/related connections back to IoT devices</span>
iptables <span class="nt">-I</span> FORWARD <span class="nt">-m</span> state <span class="nt">--state</span> ESTABLISHED,RELATED <span class="nt">-j</span> ACCEPT

<span class="c"># Allow home LAN to reach IoT LAN (for management)</span>
iptables <span class="nt">-I</span> FORWARD <span class="nt">-s</span> 192.168.1.0/24 <span class="nt">-d</span> 10.1.101.0/24 <span class="nt">-j</span> ACCEPT

<span class="c"># Block IoT from initiating connections to home LAN</span>
iptables <span class="nt">-I</span> FORWARD <span class="nt">-s</span> 10.1.101.0/24 <span class="nt">-d</span> 192.168.1.0/24 <span class="nt">-j</span> REJECT

<span class="c"># Allow IoT to reach internet</span>
iptables <span class="nt">-I</span> FORWARD <span class="nt">-s</span> 10.1.101.0/24 <span class="nt">-o</span> <span class="si">$(</span>nvram get wan_iface<span class="si">)</span> <span class="nt">-j</span> ACCEPT
</code></pre></div></div>

<p>This is the other half of the magic! It essentially inverts the normal NAT semantic:</p>

<ul>
  <li>home LAN devices <strong>can</strong> SSH or otherwise connect to IoT devices, access their web interfaces, push firmware updates, etc. They don‚Äôt see the NAT at all.</li>
  <li>IoT devices cannot reach anything on the home LAN. They don‚Äôt see the home LAN at all.</li>
</ul>

<p>The dd-wrt web interface didn‚Äôt make setting this up obvious:</p>

<p><img src="dd-wrt_administration_commands.jpg" alt="DD-WRT: Administration ‚Üí Commands" /></p>

<ol>
  <li>At first, you have no saved commands, so all you can use is the ‚ÄúCommands‚Äù text box.</li>
  <li>Enter the firewall rules.</li>
  <li>Click ‚ÄúRun Commands‚Äù to run them and see if they work.</li>
  <li>Click ‚ÄúSave Firewall‚Äù to save them.</li>
  <li><em>Next time</em>, you will have contents in the ‚ÄúFirewall‚Äù text field.</li>
  <li>Click ‚ÄúEdit‚Äù under the ‚ÄúFirewall‚Äù text field to populate the ‚ÄúCommands‚Äù text box with the firewall script.</li>
  <li>GOTO 2.</li>
</ol>

<h2 id="pihole-integration">PiHole Integration</h2>

<h3 id="the-nat-problem">The NAT Problem</h3>

<p>With basic routing working, I checked the PiHole query logs. All IoT DNS queries appeared to come from <code class="language-plaintext highlighter-rouge">192.168.1.101</code> - the IoT router‚Äôs WAN IP. NAT was hiding the individual clients.</p>

<p>This defeated a key goal. I wanted per-device DNS visibility so I could block specific IoT devices from specific domains. With everything hidden behind one IP, I could only manage IoT as a single entity.</p>

<h3 id="nat-exemption-for-dns">NAT Exemption for DNS</h3>

<p>The solution: exempt DNS traffic from NAT, allowing the original source IP through to PiHole.</p>

<p>Additions to the firewall script:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Exempt DNS to PiHole from NAT (preserve source IP)</span>
iptables <span class="nt">-t</span> nat <span class="nt">-I</span> POSTROUTING <span class="nt">-d</span> 192.168.1.254 <span class="nt">-p</span> udp <span class="nt">--dport</span> 53 <span class="nt">-j</span> ACCEPT
iptables <span class="nt">-t</span> nat <span class="nt">-I</span> POSTROUTING <span class="nt">-d</span> 192.168.1.254 <span class="nt">-p</span> tcp <span class="nt">--dport</span> 53 <span class="nt">-j</span> ACCEPT

<span class="c"># Allow IoT to reach PiHole DNS</span>
iptables <span class="nt">-I</span> FORWARD <span class="nt">-s</span> 10.1.101.0/24 <span class="nt">-d</span> 192.168.1.254 <span class="nt">-p</span> udp <span class="nt">--dport</span> 53 <span class="nt">-j</span> ACCEPT
iptables <span class="nt">-I</span> FORWARD <span class="nt">-s</span> 10.1.101.0/24 <span class="nt">-d</span> 192.168.1.254 <span class="nt">-p</span> tcp <span class="nt">--dport</span> 53 <span class="nt">-j</span> ACCEPT
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">-t nat -I POSTROUTING ... -j ACCEPT</code> rules tell iptables: ‚ÄúFor packets going to PiHole port 53, skip the <a href="https://www.netfilter.org/documentation/HOWTO/NAT-HOWTO-6.html#ss6.1">MASQUERADE rule that rewrites the source IP</a>.‚Äù The packets arrive at PiHole with their original 10.1.101.x source addresses. Normally, these packets wouldn‚Äôt be able to be responded to: the pihole is on a different subnet with a different gateway that wouldn‚Äôt know about the <code class="language-plaintext highlighter-rouge">10.1.101.0/24</code> devices! That‚Äôs what the static route on the main router is for: the pihole‚Äôs gateway actually <em>does</em> know where to send responses addressed to the <code class="language-plaintext highlighter-rouge">10.*</code> addresses.</p>

<p>After applying these rules, individual IoT IPs appeared in the PiHole logs.</p>

<h2 id="hostname-resolution">Hostname Resolution</h2>

<p>IP addresses appeared correctly, but the PiHole query log showed numeric IPs instead of hostnames. For the home LAN, PiHole displayed ‚Äúmacbook‚Äù and ‚Äúdesktop‚Äù. For IoT devices, just <code class="language-plaintext highlighter-rouge">10.1.101.134</code>.</p>

<h3 id="configuring-the-iot-routers-dns">Configuring the IoT Router‚Äôs DNS</h3>

<p>The IoT router needed to serve reverse DNS lookup queries about its own DHCP clients. This required several dnsmasq settings.</p>

<p>In Setup ‚Üí Basic Setup:</p>

<ul>
  <li><strong>Local Domain</strong>: <code class="language-plaintext highlighter-rouge">iot.local</code></li>
  <li><strong>Use DNSMasq for DNS</strong>: Enabled</li>
</ul>

<p>In Services ‚Üí Services ‚Üí Dnsmasq Infrastructure ‚Üí Additional Options:</p>

<p><img src="dd-wrt_services_services_dnsmasq-infrastructure_sm.jpg" alt="DD-WRT: Services ‚Üí Services ‚Üí Additional DNSMasq Options" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>expand-hosts
bind-interfaces
listen-address=192.168.1.101
local=/101.1.10.in-addr.arpa/
dhcp-option=6,192.168.1.254
</code></pre></div></div>

<p>Each line serves a specific purpose:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">expand-hosts</code>: Append the domain to DHCP hostnames, so we have names in the first place</li>
  <li><code class="language-plaintext highlighter-rouge">bind-interfaces</code>: Required when specifying listen-address</li>
  <li><code class="language-plaintext highlighter-rouge">listen-address=192.168.1.101</code>: Serve DNS on WAN interface only (for PiHole reverse DNS queries)</li>
  <li><code class="language-plaintext highlighter-rouge">local=/101.1.10.in-addr.arpa/</code>: Answer reverse DNS locally instead of forwarding upstream</li>
  <li><code class="language-plaintext highlighter-rouge">dhcp-option=6,192.168.1.254</code>: Tell DHCP clients to use PiHole as their DNS server (option 6 = DNS server)</li>
</ul>

<p>The <code class="language-plaintext highlighter-rouge">local=</code> line was critical. Without it, the IoT router forwarded reverse DNS queries to internet root servers, which returned NXDOMAIN for private IP addresses. With <code class="language-plaintext highlighter-rouge">local=</code>, it answers authoritatively from its own DHCP lease table.</p>

<p>I tried using <code class="language-plaintext highlighter-rouge">auth-zone</code> for authoritative DNS, which would also have prevented the forwarding of reverse DNS queries, but DD-WRT‚Äôs dnsmasq wasn‚Äôt compiled with <code class="language-plaintext highlighter-rouge">HAVE_AUTH</code> support. The router refused to start dnsmasq at all with that directive. <code class="language-plaintext highlighter-rouge">local=</code> was the way to go.</p>

<p>Note also that we‚Äôre <em>not</em> listening on the LAN interface (<code class="language-plaintext highlighter-rouge">10.1.101.1</code>), as a DHCP‚Äôing router normally would. IoT devices should use PiHole for DNS, not this router. To enforce this policy, and to allow PiHole to query us for reverse DNS, we need a few more firewall rules:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Allow reverse DNS queries FROM PiHole (via WAN interface)</span>
iptables <span class="nt">-I</span> INPUT <span class="nt">-i</span> vlan2 <span class="nt">-s</span> 192.168.1.254 <span class="nt">-p</span> udp <span class="nt">--dport</span> 53 <span class="nt">-j</span> ACCEPT
iptables <span class="nt">-I</span> INPUT <span class="nt">-i</span> vlan2 <span class="nt">-s</span> 192.168.1.254 <span class="nt">-p</span> tcp <span class="nt">--dport</span> 53 <span class="nt">-j</span> ACCEPT

<span class="c"># Block DNS queries TO the gateway from IoT clients (they should use PiHole)</span>
iptables <span class="nt">-I</span> INPUT <span class="nt">-i</span> br0 <span class="nt">-p</span> udp <span class="nt">--dport</span> 53 <span class="nt">-j</span> REJECT
iptables <span class="nt">-I</span> INPUT <span class="nt">-i</span> br0 <span class="nt">-p</span> tcp <span class="nt">--dport</span> 53 <span class="nt">-j</span> REJECT
</code></pre></div></div>

<h3 id="configuring-piholes-conditional-forwarding">Configuring PiHole‚Äôs Conditional Forwarding</h3>

<p>PiHole needs to know where to send reverse DNS queries for the IoT subnet. The web UI supports <a href="https://docs.pi-hole.net/ftldns/configfile/?h=forwarding#revservers">conditional forwarding</a>, but only for a single network - mine was already configured for the home LAN.</p>

<p>The solution: manually add a dnsmasq configuration file on the pihole server:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># /etc/dnsmasq.d/11-iot-subnet.conf</span>
rev-server<span class="o">=</span>10.1.101.0/24,192.168.1.101
</code></pre></div></div>

<p>This tells PiHole: ‚ÄúFor reverse DNS lookups of <code class="language-plaintext highlighter-rouge">10.1.101.x</code> addresses, query <code class="language-plaintext highlighter-rouge">192.168.1.101</code> (the IoT router‚Äôs WAN IP).‚Äù</p>

<p>After restarting PiHole‚Äôs DNS:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>pihole restartdns
</code></pre></div></div>

<p>Reverse DNS queries started working. <code class="language-plaintext highlighter-rouge">dig -x 10.1.101.134</code> on the PiHole server returned <code class="language-plaintext highlighter-rouge">macbook.iot.local</code>.</p>

<h3 id="the-cache-finale">The Cache Finale</h3>

<p>Everything was configured correctly. Reverse DNS worked from the command line. The PiHole <a href="https://docs.pi-hole.net/database/query-database/">FTL database</a> showed hostnames:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sqlite&gt; SELECT ip, name FROM network_addresses WHERE ip LIKE '10.1.101.%';
10.1.101.134|macbook.iot.local
10.1.101.101|gateway-device-1.iot.local
10.1.101.109|gateway-device-2.iot.local
</code></pre></div></div>

<p>But the PiHole web interface still showed IP addresses.</p>

<p>Browser cache. A hard refresh (Ctrl+Shift+R) and hostnames appeared. It may have also been a 10-minute or so wait. I didn‚Äôt test rigorously. But, it eventually started working; there was <em>some</em> kind of latency involved between proper configuration and hostnames actually showing in the Web UI.</p>

<h2 id="final-working-configuration">Final Working Configuration</h2>

<h3 id="main-router-asuswrt-merlin">Main Router (Asuswrt-Merlin)</h3>

<h4 id="lan--route">LAN ‚Üí Route</h4>

<p><strong>Static Route</strong></p>

<table>
  <thead>
    <tr>
      <th>Network/Host IP</th>
      <th>Netmask</th>
      <th>Gateway</th>
      <th>Metric</th>
      <th>Interface</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10.1.101.0/24</td>
      <td>255.255.255.0</td>
      <td>192.168.1.101</td>
      <td>¬†</td>
      <td>LAN</td>
    </tr>
  </tbody>
</table>

<h3 id="iot-router-dd-wrt">IoT Router (DD-WRT)</h3>

<h4 id="setup--basic-setup">Setup ‚Üí Basic Setup</h4>

<p><strong>WAN Connection Type</strong></p>
<ul>
  <li>Connection Type: Static IP</li>
  <li>WAN IP Address: <code class="language-plaintext highlighter-rouge">192.168.1.101/24</code></li>
  <li>Gateway: <code class="language-plaintext highlighter-rouge">192.168.1.1</code></li>
  <li>Static DNS 1: <code class="language-plaintext highlighter-rouge">192.168.1.254</code></li>
</ul>

<p><strong>Optional Settings</strong></p>
<ul>
  <li>Domain Name: <code class="language-plaintext highlighter-rouge">iot.local</code></li>
</ul>

<p><strong>Router IP</strong></p>
<ul>
  <li>Local IP Address: <code class="language-plaintext highlighter-rouge">10.1.101.1/24</code></li>
  <li>Gateway: <code class="language-plaintext highlighter-rouge">0.0.0.0</code></li>
  <li>Local DNS: <code class="language-plaintext highlighter-rouge">192.168.1.254</code></li>
</ul>

<p><strong>DHCP</strong></p>
<ul>
  <li>DHCP Type: DHCP Server</li>
  <li>DHCP Server: ‚úÖ Enable</li>
  <li>Start IP Address: <code class="language-plaintext highlighter-rouge">10.1.101.100</code></li>
  <li>Maximum DHCP Users: 50</li>
  <li>Use DNSMasq for DNS: ‚úÖ (enabled)</li>
</ul>

<h4 id="services--services">Services ‚Üí Services</h4>

<p><strong>Dnsmasq Infrastructure</strong></p>

<p><em>Additional Options:</em></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>expand-hosts
bind-interfaces
listen-address=192.168.1.101
local=/101.1.10.in-addr.arpa/
dhcp-option=6,192.168.1.254
</code></pre></div></div>

<h4 id="administration--commands">Administration ‚Üí Commands</h4>

<p><strong>Firewall</strong></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># ===== DNS Protection =====</span>
<span class="c"># Allow reverse DNS queries FROM PiHole (via WAN interface)</span>
iptables <span class="nt">-I</span> INPUT <span class="nt">-i</span> vlan2 <span class="nt">-s</span> 192.168.1.254 <span class="nt">-p</span> udp <span class="nt">--dport</span> 53 <span class="nt">-j</span> ACCEPT
iptables <span class="nt">-I</span> INPUT <span class="nt">-i</span> vlan2 <span class="nt">-s</span> 192.168.1.254 <span class="nt">-p</span> tcp <span class="nt">--dport</span> 53 <span class="nt">-j</span> ACCEPT

<span class="c"># Block DNS queries TO the gateway from IoT clients (they should use PiHole)</span>
iptables <span class="nt">-I</span> INPUT <span class="nt">-i</span> br0 <span class="nt">-p</span> udp <span class="nt">--dport</span> 53 <span class="nt">-j</span> REJECT
iptables <span class="nt">-I</span> INPUT <span class="nt">-i</span> br0 <span class="nt">-p</span> tcp <span class="nt">--dport</span> 53 <span class="nt">-j</span> REJECT
<span class="c"># ===== End DNS Protection =====</span>

<span class="c"># Allow established/related to IoT LAN</span>
iptables <span class="nt">-I</span> FORWARD <span class="nt">-m</span> state <span class="nt">--state</span> ESTABLISHED,RELATED <span class="nt">-j</span> ACCEPT

<span class="c"># Allow home LAN to reach IoT LAN</span>
iptables <span class="nt">-I</span> FORWARD <span class="nt">-s</span> 192.168.1.0/24 <span class="nt">-d</span> 10.1.101.0/24 <span class="nt">-j</span> ACCEPT

<span class="c"># Block IoT from initiating to home LAN</span>
iptables <span class="nt">-I</span> FORWARD <span class="nt">-s</span> 10.1.101.0/24 <span class="nt">-d</span> 192.168.1.0/24 <span class="nt">-j</span> REJECT

<span class="c"># ===== PiHole DNS Rules =====</span>
<span class="c"># Exempt DNS to PiHole from NAT</span>
iptables <span class="nt">-t</span> nat <span class="nt">-I</span> POSTROUTING <span class="nt">-d</span> 192.168.1.254 <span class="nt">-p</span> udp <span class="nt">--dport</span> 53 <span class="nt">-j</span> ACCEPT
iptables <span class="nt">-t</span> nat <span class="nt">-I</span> POSTROUTING <span class="nt">-d</span> 192.168.1.254 <span class="nt">-p</span> tcp <span class="nt">--dport</span> 53 <span class="nt">-j</span> ACCEPT

<span class="c"># Allow IoT to reach PiHole DNS</span>
iptables <span class="nt">-I</span> FORWARD <span class="nt">-s</span> 10.1.101.0/24 <span class="nt">-d</span> 192.168.1.254 <span class="nt">-p</span> udp <span class="nt">--dport</span> 53 <span class="nt">-j</span> ACCEPT
iptables <span class="nt">-I</span> FORWARD <span class="nt">-s</span> 10.1.101.0/24 <span class="nt">-d</span> 192.168.1.254 <span class="nt">-p</span> tcp <span class="nt">--dport</span> 53 <span class="nt">-j</span> ACCEPT
<span class="c"># ===== End PiHole DNS Rules =====</span>

<span class="c"># Allow IoT to the internet</span>
iptables <span class="nt">-I</span> FORWARD <span class="nt">-s</span> 10.1.101.0/24 <span class="nt">-o</span> <span class="si">$(</span>nvram get wan_iface<span class="si">)</span> <span class="nt">-j</span> ACCEPT
</code></pre></div></div>

<h3 id="pihole">PiHole</h3>

<h4 id="etcdnsmasqd11-iot-subnetconf"><code class="language-plaintext highlighter-rouge">/etc/dnsmasq.d/11-iot-subnet.conf</code></h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rev-server=10.1.101.0/24,192.168.1.101
</code></pre></div></div>

<h2 id="a-note-on-subnet-selection">A Note on Subnet Selection</h2>

<p>This post uses <code class="language-plaintext highlighter-rouge">10.1.101.0/24</code> throughout, but I actually started with <code class="language-plaintext highlighter-rouge">192.168.101.0/24</code>. Mid-configuration, I switched.</p>

<p>The problem was readability. The IoT router‚Äôs WAN IP was <code class="language-plaintext highlighter-rouge">192.168.1.101</code>. The IoT router‚Äôs LAN IP was <code class="language-plaintext highlighter-rouge">192.168.101.1</code>. When debugging firewall rules and routing tables, my brain kept swapping them. Is this the router‚Äôs address on the home network, or its address on its own network? Which side of the NAT am I looking at?</p>

<p>Switching to <code class="language-plaintext highlighter-rouge">10.1.101.0/24</code> made everything clearer. The <code class="language-plaintext highlighter-rouge">192.168.x.x</code> addresses are home LAN. The <code class="language-plaintext highlighter-rouge">10.x.x.x</code> addresses are IoT. No ambiguity. If you‚Äôre setting up something similar, pick subnets that are visually distinct.</p>

<p>The pivot itself was straightforward:</p>

<ol>
  <li>Change IoT router‚Äôs LAN IP from <code class="language-plaintext highlighter-rouge">192.168.101.1</code> to <code class="language-plaintext highlighter-rouge">10.1.101.1</code></li>
  <li>Update DHCP range to <code class="language-plaintext highlighter-rouge">10.1.101.100-149</code></li>
  <li>Update main router‚Äôs static route destination to <code class="language-plaintext highlighter-rouge">10.1.101.0/24</code></li>
  <li>Update all iptables rules referencing the IoT subnet</li>
  <li>Update PiHole‚Äôs conditional forwarding config</li>
  <li>Reboot IoT router, renew DHCP leases on clients, and reboot the pihole server</li>
</ol>

<h2 id="fin">Fin</h2>

<p>The petcare hub works. It‚Äôs directly connected to a router, which is all its defective firmware ever needed. And the IoT network is finally isolated, with full per-device visibility in PiHole.</p>

<p>All because a petcare company couldn‚Äôt write firmware that can handle being connected to a network switch.</p>]]></content><author><name>Texarkanine</name></author><category term="blog" /><category term="record" /><category term="dd-wrt" /><category term="dns" /><category term="home-networking" /><category term="iot" /><category term="iptables" /><category term="networking" /><category term="pihole" /><summary type="html"><![CDATA[A petcare IoT device ‚Äúbroke.‚Äù It had worked for a year, connected through two switches between it and my main router. Then it stopped being able to connect to the manufacturer‚Äôs servers. The manufacturer‚Äôs support script was predictable: ‚ÄúConnect it directly to your router.‚Äù I did. It worked.]]></summary></entry><entry><title type="html">Desire Makes Artists, Even With GenAI</title><link href="https://blog.cani.ne.jp/2026/01/01/desire-makes-artists-even-with-genai.html" rel="alternate" type="text/html" title="Desire Makes Artists, Even With GenAI" /><published>2026-01-01T00:00:00+00:00</published><updated>2026-01-01T00:00:00+00:00</updated><id>https://blog.cani.ne.jp/2026/01/01/desire-makes-artists-even-with-genai</id><content type="html" xml:base="https://blog.cani.ne.jp/2026/01/01/desire-makes-artists-even-with-genai.html"><![CDATA[<h2 id="thesis">Thesis</h2>

<blockquote>
  <p>The desire to create is what makes an artist. That‚Äôs true for some people using generative AI - and it‚Äôs also why there will always be human artists.</p>
</blockquote>

<h2 id="what-making-art-is">What Making Art Is</h2>

<p>Making art is the human creative undertaking. The desire to create something, to express, to bring ideas into the world - that generative impulse is what makes an artist make art.</p>

<p>Many things are produced by people with artistic skill, often bringing that skill to bear on products with dual purposes: expression and function. Clothing is an excellent example. There is absolutely clothing that serves very little purpose other than to be aesthetic, and there is definitely clothing that serves very little purpose other than to be functional. Most clothing exists in between.</p>

<p>Before the industrial revolution, clothing was made by hand by what we might call artisans - makers who often had artistic talent. You would get production of goods with art infused during the process, because that‚Äôs what humans do when they make things. As cloth-making industrialized, we were able to separate the artist from the artisan. Machines operationalized the good production, but artists still produced artistic clothing. Now Chinese factories crank out dirt-cheap t-shirts that technically work, while artistic seamstresses and clothiers hand-make bespoke luxury clothing for the fashion runway or demure custom shops.</p>

<p>We have separated the art from the good. Both exist.</p>

<h2 id="function-is-unforgiving">Function Is Unforgiving</h2>

<p>The key takeaway of this separation: function is unforgiving. If the thing does not work, it cannot exist in most contexts. Aesthetics without function is a luxury, and luxury is almost definitionally a minority undertaking.</p>

<p>Most goods only need, and are only wanted, to satisfy a task. It is much rarer that a good is primarily for satisfying aesthetics. Once you can separate the artist from the artisan and operationalize the production that the artisan used to handle, you end up with the majority of production being more or less purely functional - form as an afterthought.</p>

<p>This absolutely happened with clothing. It absolutely happened with dwellings. It has absolutely happened with most housewares and furniture. It is, in fact, what happens when humans manage to build tools and processes that operationalize and industrialize the production of a good that previously had to be handmade.</p>

<h2 id="portraits">Portraits</h2>

<p>Consider portraits. Back in the oil painting days, before photography, portraits were a big deal. They were rare. They were labor-intensive. If you wanted a portrait of yourself, you had to shell out, and it was quite an ordeal to get one made. Once done, it was quite a piece - a centerpiece, a focus piece - because only the artistic artisan could make one for you.</p>

<p>Nowadays, we have cameras in electronic devices in basically every pocket. Everybody who wants a portrait of themselves can get one. They can get a piece of visual media that they can look at and see themselves.</p>

<p>The oil painting - professionally staged, framed, an heirloom piece hanging on the wall of your house - is still a luxury art piece. But most people who wanted portraits didn‚Äôt actually need the whole shebang. They just wanted to see themselves in a piece of visual media. And they can get that now with the tools and processes we have built into smartphone cameras. It‚Äôs trivially easy to get a technical portrait of yourself where you can see yourself.</p>

<p>So most people who just wanted the outcome - a piece of visual media in which they could see themselves - get that easily and don‚Äôt advance to finding an artist to pay for a professional heirloom portrait.</p>

<h2 id="visual-media-today">Visual Media Today</h2>

<p>We are seeing this same separation today with visual media and generative AI.</p>

<p>Previously, in order to make a piece of visual media that other people could see - regardless of the purpose - you had to engage some form of artist-artisan combination. Maybe a graphic designer to produce the advertising copy for your company - function-forward visual media, but you were still absolutely using a human‚Äôs artistic talent to do it. Or maybe you wanted a book illustration, a comic, a particular scene. Either way, you needed the human artist-artisan combo.</p>

<p>Now that we have generative AI, many of those people can - just like they were doing with a selfie on their smartphone - get a good-enough visual rendering of their idea to satisfy what they needed. And they stop there.</p>

<p>Those people didn‚Äôt actually need art. They didn‚Äôt actually <em>want</em> art. They just needed a piece of visual media. And what we have now is the ability to separate the artisan from the artist once more, as humans have been doing since the beginning of technology, but in the domain of visual media.</p>

<h2 id="is-it-art-are-they-artists">Is It Art? Are They Artists?</h2>

<p>We will punt on ‚Äúis it art?‚Äù because that is an age-old question that has always been hotly debated, whose answer has shifted time and time again and is ultimately subjective.</p>

<p>Instead, let‚Äôs look at the people making these things and ask if they are artists.</p>

<p>As you might infer from the separation of artist and artisan, indeed, some of them are not. The people who would have needed a professional graphic designer - the artist-artisan combination - but now can use generative AI to get the visual media that communicates what they need? They‚Äôre using the operationalized, industrialized visual media production pipeline.</p>

<p>That‚Äôs fine. We used to have weavers weaving things on looms. We still have looms, but the overwhelming majority of them are industrial-scale, and the people that work in those factories we don‚Äôt really refer to as weavers anymore. They‚Äôre just employees. Workers.</p>

<p>So the people using generative AI just to make the visual media that serves a function - where form is not the driving purpose - are not artists. Because they‚Äôre not engaging in the creative undertaking of desiring to manifest a vision in the world. They don‚Äôt seek to share the aesthetic outcome. They don‚Äôt seek gratification from the experience of creating. They just seek the finished product so that it may perform its function.</p>

<p>And that‚Äôs fine. That‚Äôs allowed. People who buy t-shirts from factories that make t-shirts are not engaging with artists. You can also get a t-shirt that was handmade by an artist somewhere. And that‚Äôs okay too.</p>

<h2 id="the-artists-among-them">The Artists Among Them</h2>

<p>But some of those generative AI users don‚Äôt see a tool that gets them to an outcome faster. They see a tool that allows them to manifest aesthetics that were trapped in their head before.</p>

<p>These people are no different than a photographer picking up a camera or - pay attention to how we call these now - an <strong>artist</strong> picking up a mouse or a Wacom tablet instead of a pen or a pencil or a paintbrush, because the digital toolset is more amenable to manifesting their vision.</p>

<p>Those people who see generative AI as ‚Äúoh my goodness, I can finally create these visual experiences that I did not have a way to create before‚Äù - <strong>those people are artists.</strong></p>

<p>They are artists because they seek, through the act of creation, to experience and share the experience. That is what drives the artistic process. Even after visual media creation is fully industrialized - even after most people are just having the machines make the visual media that they need for their outcomes - we need not fear the loss of artists.</p>

<p>There will still be humans doing it by hand, because they seek the experience of <strong>doing</strong> the creating as an end unto itself.</p>]]></content><author><name>Niko</name></author><category term="blog" /><category term="essay" /><category term="ai" /><category term="art" /><category term="generative-ai" /><summary type="html"><![CDATA[The desire to create is what makes an artist. That's why some people using generative AI are artists - and it's also why there will always be human artists.]]></summary></entry></feed>