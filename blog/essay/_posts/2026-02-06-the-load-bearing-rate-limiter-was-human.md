---
layout: post
title: "The Load-Bearing Rate Limiter Was Human"
author: texarkanine
tags:
  - ai
  - economics
  - productivity
---

## Thesis

> It is now possible to do knowledge work faster than customers can pay for it, and faster than knowledge work**ers** can get **paid** for it.

The money-to-productivity pipeline no longer requires time as a fixed-rate intermediary, and neither companies nor individuals are ready for what that means.

## The Transaction That Changed My Mind

I had a task. With Claude Sonnet, I could babysit the model through understanding, designing, planning, checking, and committing over the course of about four hours. Cost: maybe $5 in Cursor usage and four hours of my undivided attention.

With Opus, I wrote a spec, walked away, and came back to a finished product. Thirty minutes. About $30.

The dollar cost was 6x higher. The *me* cost was roughly 8x lower. I wasn't writing code in either case - the difference was whether I had to stand there being the bottleneck/manager or whether I could go be a person for a while.

Dollars are painful when they leave your wallet... But I spent my *day* on the cheap version. And I only get so many of those (days, that is).

That $30/30min vs $5/4hr comparison is the transaction that reframed everything for me because it surfaced a question that sounds simple but has enormous consequences: 

> who really came out ahead?

## The 1X Bottleneck

You might be tempted to normalize my comparative costs above to $60/hr vs $1.25/hr, but that's not quite right - it assumes that each hour is the same... and they're not, not anymore.

Historically, the path from money to productivity in knowledge work has always been:

**Money -> Time (1X) -> Productivity**

A company pays a salary. That salary buys a commitment to a year of work hours. The company tries to hire the human who will convert those hours into the most output. Maybe they pay $50K and get a baseline, or $300K for someone who produces genuinely 10x the value - but even the mythical 10X engineer lives through time at 1X speed. You could buy a *better converter*, but you could never buy a *faster clock*. No matter the conversion rate, it was always going to run at 1X speed: you can't overclock a human.

In my experience, as of late 2025, frontier AI models have broken that constraint. Nevermind the early-2026 drops of Opus 4.6 and GPT-5.3-Codex. The middle of the pipeline is no longer a human metabolizing time. It's tokens, and tokens scale in a way that humans don't.

When crypto miners discovered GPUs could convert electricity into money faster than entertained gamers could, miners repriced the entire GPU market in the blink of an eye. AI is doing the same thing to knowledge labor: a more efficient converter has arrived, and it's about to reprice everything.

## Productivity Hyperscaled. Revenue Hasn't.

The immediate, observable consequence: productivity is going vertical while revenue takes the stairs.

After my Opus revelation, I burned through the $200 of my Cursor Ultra budget in barely five days. The productivity was real - tasks that would have taken weeks were landing in hours. But I couldn't sustain it. I didn't have $1,000/month for this. So I fell back to the slow path, rationing tokens, babysitting models again. Fifteen days into austerity and counting and it feels like Slow Wifi.

Before, though, projects that would have taken a year of spare evenings now cost $50 and a Saturday morning. And that was amazing! Refreshing! Exciting! But! These projects were never going to generate revenue. When they cost a year of spare time, that was fine - the time was "free" in the sense that I wasn't selling it to anyone. Now that they are costing me actual dollars, the lack of a revenue model becomes a real problem.

Companies are going to hit this same wall at scale. They budget annually: a year of salary against a year of expected output against a year of expected revenue. When a skilled AI-wielding engineer burns through a year of planned work in two months, they also burn through a year of token budget. The work is done, the money is spent, and now everyone's standing around the finish line with ten months of operational costs and no new revenue. The constraint isn't distribution - you *can* ship a hundred improvements in a month. The constraint is absorption. Human customers adopt, integrate, and respond at human speed. Drop ten improvements on a product in a week and your conversion rate doesn't budge ten-fold that week. The demand side has its own metabolism, and it's still running at 1X.

You don't have a productivity problem anymore. You have a *digestion* problem.

## Constant Discernment!

The intuitive response to unprecedented productivity is "do everything faster." The correct response is almost the opposite: be more discerning about what you unleash productivity on.

If you can finish a project in a week, you could theoretically finish at least four, maybe a dozen, in a month. But you don't want to, because you'll burn all your cash before the market has a chance to respond to any of them. The capability is there. The absorption capacity isn't.

This is a genuinely novel constraint for most knowledge workers and the companies that employ them. We've spent decades optimizing for "how do we get more done?" and now the answer is "easily, but that's no longer the right question." The right question is 

> Which things, done now, will generate returns before the budget runs out?

When the human was the rate limiter, spend and revenue were temporally coupled - a year of salary forced a year of output and that happened over a year of revenue collection. Remove the rate limiter from the supply side (output and spend) but not the demand side (customer adoption and revenue) and one side can compress to months while revenue still takes its year to arrive. The calendar was load-bearing too.

## The Multi-Tenancy Engineer

Follow the math to its conclusion.

If you can convert a company's entire annual productivity budget into output in one-tenth the time, you're meaningfully working about 80 to 90 minutes of an eight-hour day (accounting for overhead & that I'm doing napkin math here). The company got every dollar's worth of productivity it paid for. You just delivered it fast.

The logical outcome is one engineer, multiple employers. Nobody is worse off. Company A paid for X productivity and got X productivity. The fact that it took you 90 minutes instead of 8 hours is a property of the converter, not the contractual agreement to convert. You haven't cheated anyone; you've simply become a more efficient machine.

This used to be frowned upon. It might still be, but the reasoning behind the taboo - that working for multiple employers means each one gets less than they paid for - breaks down when the bottleneck was never your effort but the clock you were living through. The multi-tenancy engineer isn't moonlighting. They're just... done.

## Dark Corollaries

The multi-tenancy engineer is perhaps an optimistic outcome. A pessimistic one is that companies see six hours of surplus capacity per day and reprice labor downward. "We'll give you a token budget instead of a raise." They can't ask for *more* productivity, because of the revenue scaling constraint - the marginal return on productivity has hit zero. But someone's going to look at a 10x engineer with six free hours and want to capture that spread.

*Arbitrage* is the word for this entire landscape.

Engineers arbitrage their own time across employers. Companies try to arbitrage compensation against token costs. Model providers arbitrage compute against everyone's exchange rates & cash flow. VCs arbitrage the information asymmetry of who understands the new exchange rates and who doesn't.

Arbitrage, all the way down. Whoever recognizes the new rates first wins. Whoever clings to the old rates longest gets arbitraged themselves.

A shadow looms among the optimistic outcome too, though: If the multi-tenancy engineer pans out and works for, say, 3 companies, delivering the 1x annual productivity that each can actually afford... that's potentially two other humans who don't get hired. The productivity gains introduce a booming appetite for employment but the *supply* of employment is gated by revenue to pay for it, which remains - for now at least - running at the 1X speed of human customers.

Timing is everything here - if the multi-tenancy engineer becomes the new normal *slowly*, everything could have time to adapt. If market absorption gets a kick in the pants from AI and scales up to match the capacity to produce, the actual spread to arbitrage (and the disruption it invites) could be small. If, if, if...

## What to Do

I don't have a clean answer. Some fragments:

Watch whether revenue scaling follows productivity scaling. If it doesn't, the gap between what you *can* build and what the market will pay for is your actual constraint. Not your engineering capacity. Not your headcount. The market's ability to digest what you ship.

Be discerning. Strategic restraint in the face of unprecedented capability is counterintuitive, but burning cash faster than revenue arrives is how companies die. The ability to ship isn't the bottleneck anymore: market absorption is... and many people haven't noticed yet.

If you're an individual knowledge worker, start thinking about what it means when you can fulfill everything a company can afford to pay you for in a fraction of the time it used to take. That surplus capacity is *yours*, even if the cultural norms haven't caught up yet.

If you're an employer, consider thinking about token budgets not as a cost-center, nor as a line-item on a team's budget, but as a *payroll* expense. You pay your humans a salary to secure a conversion of that money into productivity, over time. LLMs are the new converters on the block, just running on a different clock. Budget against the new reality!

And keep an eye on the arbitrage. It's coming from every direction and your position in the spread determines whether this transition is a windfall or a haircut. Right now, the spread is wide - which means the stakes are high and the window won't stay open forever.

---

### Postscript

The literal morning after I wrote this, Anthropic [dropped Claude Opus 4.6 Fast](https://x.com/claudeai/status/2020207322124132504), 2.5x faster at 6x the cost - so the numbers in my "aha" would now be $180/12min vs $5/4hr. Again, normalizing it to $900/hr vs $1.25/hr is wrong - the calculus is to pick one:

1. Spend a month of Saturdays on a hobby project, and finish it for $0 in token costs.
2. Spend a whole weekend on it for $20 in token costs.
3. Complete the whole project in under an hour for $900 and have the rest of the *month's* weekends free.

This sudden 2.5x multiplication of the money-to-productivity ratio - that was already on its way to the moon - just makes the effects described above all the more poignant!

Some of you might say that choice 1 is the obvious choice, because you *enjoy the hobby*. This is okay and absolutely allowed and if it's true for you then none of this applies to your hobby right now – [you're an artist]({% post_url blog/essay/2026-01-01-desire-makes-artists-even-with-genai %}#the-artists-among-them) in this moment. The knowledge-work industry, however, is not – and you *will* at the very least bear witness as it struggles to adapt to the new calculus.

### Post-Postscript

A few days later, [Steve Yegge](https://steve-yegge.medium.com/) of [Gas Town](https://steve-yegge.medium.com/welcome-to-gas-town-4f25ee16dd04) fame has written about what I will claim is this same phenomenon, but from a different angle. [The AI Vampire](https://steve-yegge.medium.com/the-ai-vampire-eda6e4f07163) explores some *additional* interesting implications of "the new calculus," and has some great lines that echo:

> $/hr To The Rescue ... Someone else might control the numerator. But you control the denominator.

> With a 10x boost, if you give an engineer Claude Code, then once they’re fluent, their work stream will produce nine additional engineers’ worth of value.
><br><br>
>For someone.
> <br><br>
> But who actually gets to keep that value?